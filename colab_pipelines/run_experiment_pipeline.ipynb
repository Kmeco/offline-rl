{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_experiment_pipeline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNK9Md+pl+RECkznNSExE35",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kmeco/offline-rl/blob/master/colab_pipelines/run_experiment_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a0UPcT4GtDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Install necessary dependencies.\n",
        "\n",
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "!pip install gym\n",
        "\n",
        "!pip install imageio\n",
        "!pip install PILLOW\n",
        "!pip install pyglet\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "!pip install dm-acme\n",
        "!pip install dm-acme[reverb]\n",
        "!pip install dm-acme[tf]\n",
        "!pip install dm-acme[envs]\n",
        "\n",
        "!pip3 install gym-minigrid\n",
        "!pip install wandb\n",
        "!pip uninstall -y tb-nightly tensorboardX tensorboard && pip install tensorboard\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE_OnCbhLCIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wandb login ... # put your own wandb api id here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tjy6m8jLuwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf offline-rl\n",
        "!git clone https://github.com/Kmeco/offline-rl.git\n",
        "!cp -r offline-rl/experiments/* ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWp_INQceB5E",
        "colab_type": "text"
      },
      "source": [
        "Download the appropriate dataset (use a dataset tag from wandb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk_ZYrYU3kyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "a9f40c14-0699-447f-8603-9f0841c97d0a"
      },
      "source": [
        "import wandb, os\n",
        "run = wandb.init()\n",
        "environment_name = 'MiniGrid-Empty-Random-6x6-v0' # @param ['MiniGrid-Empty-Random-6x6-v0', 'MiniGrid-DistShift1-v0']\n",
        "dataset_tag = \"random-eps1\" #@param {type:\"string\"}\n",
        "\n",
        "artifact = run.use_artifact(f'kmeco/offline-rl/{environment_name}:{dataset_tag}', type='dataset')\n",
        "artifact_dir = artifact.download()\n",
        "\n",
        "dataset_dir = os.path.join(artifact_dir, dataset_tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/kmeco/uncategorized\" target=\"_blank\">https://app.wandb.ai/kmeco/uncategorized</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/kmeco/uncategorized/runs/30kg1t4e\" target=\"_blank\">https://app.wandb.ai/kmeco/uncategorized/runs/30kg1t4e</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.7 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeWUFQDTeIVe",
        "colab_type": "text"
      },
      "source": [
        "Run an experiment for n number of times with random initialisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghdvJ1UNbtHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4916dcd-b2de-4b08-b86f-30b332c64a74"
      },
      "source": [
        "for i in range(3):\n",
        "  !python run_offline_cql.py --dataset_dir=$dataset_dir \\\n",
        "                            --environment_name=$environment_name \\\n",
        "                            --epochs=40 \\\n",
        "                            --cql_alpha=1 \\\n",
        "                            --logs_tag='cql-1.-random-eps0-Empty-Random-6x6-1step' \\\n",
        "                            --max_eval_episode_len=500 \\\n",
        "                            --n_step_returns=1 \\\n",
        "                            --learning_rate=1e-4 \\\n",
        "                            --translate_lse=100. \\\n",
        "                            --wandb_id=''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_200732-1599595652\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599595652\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599595652\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "_____Evaluating counts for all state action pairs_____ \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:12<00:00, 79.72it/s]\n",
            "I0908 20:07:49.581229 140435675182976 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]INFO:tensorflow:Assets written to: /root/acme/eb523ebe-f20e-11ea-bb72-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:07:50.797693 140435675182976 builder_impl.py:775] Assets written to: /root/acme/eb523ebe-f20e-11ea-bb72-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:07:50.801122 140435675182976 savers.py:156] Saving checkpoint: /root/acme/eb523ebe-f20e-11ea-bb72-0242ac1c0002/checkpoints/cql_learner\n",
            "[Learner] Cql Loss = 0.032 | Critic Loss = 0.025 | Learner Steps = 83 | Push Down = 0.607 | Push Up = 0.600 | Q Average = 0.550 | Q Variance = 0.010 | Regularizer = 0.007 | Walltime = 8.993\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 1 | Learner Steps = 100 | Steps = 4 | Steps Per Second = 17.715 | Walltime = 10.821\n",
            "  2%|‚ñà                                           | 1/40 [00:14<09:25, 14.51s/it][Learner] Cql Loss = 0.015 | Critic Loss = 0.011 | Episodes = 10 | Learner Steps = 147 | Push Down = 0.677 | Push Up = 0.672 | Q Average = 0.623 | Q Variance = 0.008 | Regularizer = 0.004 | Steps = 1317 | Walltime = 19.034\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 11 | Learner Steps = 200 | Steps = 1321 | Steps Per Second = 624.966 | Walltime = 24.690\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:27<08:51, 13.98s/it][Learner] Cql Loss = 0.008 | Critic Loss = 0.005 | Episodes = 20 | Learner Steps = 221 | Push Down = 0.843 | Push Up = 0.841 | Q Average = 0.775 | Q Variance = 0.009 | Regularizer = 0.003 | Steps = 1966 | Walltime = 29.088\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 21 | Learner Steps = 300 | Steps = 1970 | Steps Per Second = 596.078 | Walltime = 37.340\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:39<08:15, 13.40s/it][Learner] Cql Loss = 0.008 | Critic Loss = 0.007 | Episodes = 30 | Learner Steps = 302 | Push Down = 0.778 | Push Up = 0.776 | Q Average = 0.732 | Q Variance = 0.004 | Regularizer = 0.002 | Steps = 2076 | Walltime = 39.192\n",
            "[Learner] Cql Loss = 0.004 | Critic Loss = 0.003 | Episodes = 30 | Learner Steps = 397 | Push Down = 0.841 | Push Up = 0.840 | Q Average = 0.803 | Q Variance = 0.002 | Regularizer = 0.002 | Steps = 2076 | Walltime = 49.226\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 31 | Learner Steps = 400 | Steps = 2079 | Steps Per Second = 540.503 | Walltime = 49.602\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [00:51<07:47, 12.99s/it][Learner] Cql Loss = 0.005 | Critic Loss = 0.002 | Episodes = 40 | Learner Steps = 478 | Push Down = 0.858 | Push Up = 0.854 | Q Average = 0.823 | Q Variance = 0.002 | Regularizer = 0.004 | Steps = 2195 | Walltime = 59.306\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 41 | Learner Steps = 500 | Steps = 2200 | Steps Per Second = 616.719 | Walltime = 61.640\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [01:03<07:26, 12.76s/it][Learner] Cql Loss = 0.003 | Critic Loss = 0.001 | Episodes = 50 | Learner Steps = 557 | Push Down = 0.906 | Push Up = 0.905 | Q Average = 0.872 | Q Variance = 0.002 | Regularizer = 0.002 | Steps = 2244 | Walltime = 69.381\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 51 | Learner Steps = 600 | Steps = 2253 | Steps Per Second = 726.608 | Walltime = 73.874\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [01:15<07:05, 12.51s/it][Learner] Cql Loss = 0.002 | Critic Loss = 0.001 | Episodes = 60 | Learner Steps = 640 | Push Down = 0.918 | Push Up = 0.917 | Q Average = 0.881 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2288 | Walltime = 79.382\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 61 | Learner Steps = 700 | Steps = 2293 | Steps Per Second = 575.998 | Walltime = 85.756\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [01:27<06:46, 12.32s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 70 | Learner Steps = 721 | Push Down = 0.943 | Push Up = 0.942 | Q Average = 0.904 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2339 | Walltime = 89.406\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 71 | Learner Steps = 800 | Steps = 2344 | Steps Per Second = 665.446 | Walltime = 97.776\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [01:39<06:34, 12.34s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 80 | Learner Steps = 801 | Push Down = 0.947 | Push Up = 0.946 | Q Average = 0.913 | Q Variance = 0.001 | Regularizer = 0.001 | Steps = 2398 | Walltime = 99.543\n",
            "[Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 80 | Learner Steps = 896 | Push Down = 0.943 | Push Up = 0.942 | Q Average = 0.907 | Q Variance = 0.001 | Regularizer = 0.001 | Steps = 2398 | Walltime = 109.649\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 81 | Learner Steps = 900 | Steps = 2402 | Steps Per Second = 646.197 | Walltime = 110.064\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [01:51<06:20, 12.26s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 90 | Learner Steps = 980 | Push Down = 0.934 | Push Up = 0.933 | Q Average = 0.893 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2579 | Walltime = 119.769\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 91 | Learner Steps = 1000 | Steps = 2587 | Steps Per Second = 650.343 | Walltime = 121.968\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [02:03<06:03, 12.11s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 100 | Learner Steps = 1054 | Push Down = 0.950 | Push Up = 0.949 | Q Average = 0.907 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2639 | Walltime = 129.890\n",
            "[Evalloop] Episode Length = 12 | Episode Return = 0.978 | Episodes = 101 | Learner Steps = 1100 | Steps = 2651 | Steps Per Second = 680.847 | Walltime = 135.067\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [02:17<06:04, 12.57s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1128 | Push Down = 0.953 | Push Up = 0.952 | Q Average = 0.914 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2708 | Walltime = 140.003\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 111 | Learner Steps = 1200 | Steps = 2713 | Steps Per Second = 629.851 | Walltime = 147.680\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [02:29<05:47, 12.41s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 120 | Learner Steps = 1210 | Push Down = 0.957 | Push Up = 0.957 | Q Average = 0.913 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 2768 | Walltime = 150.066\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 121 | Learner Steps = 1300 | Steps = 2772 | Steps Per Second = 431.446 | Walltime = 159.540\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [02:41<05:30, 12.26s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 130 | Learner Steps = 1301 | Push Down = 0.948 | Push Up = 0.947 | Q Average = 0.903 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2834 | Walltime = 160.961\n",
            "[Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 130 | Learner Steps = 1396 | Push Down = 0.952 | Push Up = 0.952 | Q Average = 0.913 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2834 | Walltime = 170.970\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 131 | Learner Steps = 1400 | Steps = 2841 | Steps Per Second = 678.157 | Walltime = 171.389\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [02:53<05:15, 12.14s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1479 | Push Down = 0.951 | Push Up = 0.951 | Q Average = 0.898 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2889 | Walltime = 181.064\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 141 | Learner Steps = 1500 | Steps = 2892 | Steps Per Second = 629.965 | Walltime = 183.280\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [03:05<05:05, 12.21s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 150 | Learner Steps = 1557 | Push Down = 0.961 | Push Up = 0.960 | Q Average = 0.916 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2946 | Walltime = 191.121\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 151 | Learner Steps = 1600 | Steps = 2951 | Steps Per Second = 653.400 | Walltime = 195.524\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [03:17<04:49, 12.06s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 160 | Learner Steps = 1638 | Push Down = 0.964 | Push Up = 0.963 | Q Average = 0.918 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3003 | Walltime = 201.156\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 161 | Learner Steps = 1700 | Steps = 3006 | Steps Per Second = 462.335 | Walltime = 208.071\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [03:29<04:41, 12.23s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 170 | Learner Steps = 1716 | Push Down = 0.952 | Push Up = 0.952 | Q Average = 0.911 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3059 | Walltime = 211.183\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 171 | Learner Steps = 1800 | Steps = 3063 | Steps Per Second = 638.597 | Walltime = 220.067\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [03:41<04:27, 12.14s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 180 | Learner Steps = 1801 | Push Down = 0.962 | Push Up = 0.962 | Q Average = 0.911 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3105 | Walltime = 221.476\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 180 | Learner Steps = 1895 | Push Down = 0.958 | Push Up = 0.958 | Q Average = 0.906 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3105 | Walltime = 231.567\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 181 | Learner Steps = 1900 | Steps = 3112 | Steps Per Second = 682.333 | Walltime = 232.082\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [03:53<04:13, 12.09s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 190 | Learner Steps = 1980 | Push Down = 0.953 | Push Up = 0.953 | Q Average = 0.903 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3156 | Walltime = 241.672\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 191 | Learner Steps = 2000 | Steps = 3159 | Steps Per Second = 618.052 | Walltime = 243.800\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [04:06<04:04, 12.21s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 200 | Learner Steps = 2054 | Push Down = 0.957 | Push Up = 0.957 | Q Average = 0.909 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3213 | Walltime = 251.695\n",
            "[Evalloop] Episode Length = 10 | Episode Return = 0.982 | Episodes = 201 | Learner Steps = 2100 | Steps = 3223 | Steps Per Second = 538.463 | Walltime = 256.506\n",
            "/content/visualization.py:111: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(17, 12))\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 21/40 [04:18<03:50, 12.15s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 210 | Learner Steps = 2137 | Push Down = 0.951 | Push Up = 0.951 | Q Average = 0.893 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3275 | Walltime = 261.733\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 211 | Learner Steps = 2200 | Steps = 3282 | Steps Per Second = 729.100 | Walltime = 268.280\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [04:29<03:36, 12.02s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 220 | Learner Steps = 2221 | Push Down = 0.950 | Push Up = 0.950 | Q Average = 0.902 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3334 | Walltime = 271.741\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 221 | Learner Steps = 2300 | Steps = 3338 | Steps Per Second = 641.086 | Walltime = 279.998\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [04:41<03:22, 11.93s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 230 | Learner Steps = 2304 | Push Down = 0.948 | Push Up = 0.948 | Q Average = 0.898 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3379 | Walltime = 281.751\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 230 | Learner Steps = 2400 | Push Down = 0.949 | Push Up = 0.948 | Q Average = 0.896 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3379 | Walltime = 291.803\n",
            "[Evalloop] Episode Length = 2 | Episode Return = 0.996 | Episodes = 231 | Learner Steps = 2400 | Steps = 3381 | Steps Per Second = 534.306 | Walltime = 291.803\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [04:53<03:10, 11.91s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 240 | Learner Steps = 2482 | Push Down = 0.943 | Push Up = 0.943 | Q Average = 0.885 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3431 | Walltime = 301.857\n",
            "[Evalloop] Episode Length = 2 | Episode Return = 0.996 | Episodes = 241 | Learner Steps = 2500 | Steps = 3433 | Steps Per Second = 508.709 | Walltime = 303.826\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [05:05<02:58, 11.92s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 250 | Learner Steps = 2565 | Push Down = 0.951 | Push Up = 0.951 | Q Average = 0.897 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3468 | Walltime = 311.931\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 251 | Learner Steps = 2600 | Steps = 3475 | Steps Per Second = 518.035 | Walltime = 315.509\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [05:17<02:45, 11.85s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 260 | Learner Steps = 2649 | Push Down = 0.953 | Push Up = 0.953 | Q Average = 0.901 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3516 | Walltime = 321.948\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 261 | Learner Steps = 2700 | Steps = 3521 | Steps Per Second = 660.978 | Walltime = 327.218\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [05:29<02:36, 12.07s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 270 | Learner Steps = 2725 | Push Down = 0.954 | Push Up = 0.954 | Q Average = 0.901 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3562 | Walltime = 331.996\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 271 | Learner Steps = 2800 | Steps = 3571 | Steps Per Second = 702.603 | Walltime = 339.918\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [05:41<02:24, 12.01s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 280 | Learner Steps = 2808 | Push Down = 0.944 | Push Up = 0.944 | Q Average = 0.885 | Q Variance = 0.005 | Regularizer = 0.000 | Steps = 3617 | Walltime = 342.098\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 281 | Learner Steps = 2900 | Steps = 3620 | Steps Per Second = 647.969 | Walltime = 351.681\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [05:53<02:11, 11.93s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 290 | Learner Steps = 2901 | Push Down = 0.946 | Push Up = 0.946 | Q Average = 0.890 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3656 | Walltime = 353.084\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 290 | Learner Steps = 2996 | Push Down = 0.951 | Push Up = 0.951 | Q Average = 0.894 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3656 | Walltime = 363.151\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 291 | Learner Steps = 3000 | Steps = 3661 | Steps Per Second = 672.552 | Walltime = 363.567\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [06:05<01:59, 11.92s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 300 | Learner Steps = 3078 | Push Down = 0.954 | Push Up = 0.954 | Q Average = 0.902 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3715 | Walltime = 373.225\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 301 | Learner Steps = 3100 | Steps = 3724 | Steps Per Second = 667.611 | Walltime = 375.491\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [06:17<01:47, 11.93s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 310 | Learner Steps = 3162 | Push Down = 0.957 | Push Up = 0.957 | Q Average = 0.898 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3767 | Walltime = 383.244\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 311 | Learner Steps = 3200 | Steps = 3773 | Steps Per Second = 695.515 | Walltime = 387.289\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [06:28<01:35, 11.89s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 320 | Learner Steps = 3245 | Push Down = 0.966 | Push Up = 0.966 | Q Average = 0.906 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3814 | Walltime = 393.347\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 321 | Learner Steps = 3300 | Steps = 3818 | Steps Per Second = 636.175 | Walltime = 399.244\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [06:40<01:23, 11.90s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 330 | Learner Steps = 3327 | Push Down = 0.950 | Push Up = 0.950 | Q Average = 0.889 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3873 | Walltime = 403.371\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 331 | Learner Steps = 3400 | Steps = 3876 | Steps Per Second = 588.371 | Walltime = 410.778\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [06:53<01:12, 12.16s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 340 | Learner Steps = 3401 | Push Down = 0.954 | Push Up = 0.954 | Q Average = 0.892 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3930 | Walltime = 413.402\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 340 | Learner Steps = 3497 | Push Down = 0.965 | Push Up = 0.965 | Q Average = 0.901 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3930 | Walltime = 423.492\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 341 | Learner Steps = 3500 | Steps = 3936 | Steps Per Second = 710.377 | Walltime = 423.795\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 35/40 [07:05<01:00, 12.04s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 350 | Learner Steps = 3582 | Push Down = 0.953 | Push Up = 0.953 | Q Average = 0.889 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3978 | Walltime = 433.565\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 351 | Learner Steps = 3600 | Steps = 3987 | Steps Per Second = 633.071 | Walltime = 435.422\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [07:17<00:47, 11.93s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 360 | Learner Steps = 3666 | Push Down = 0.948 | Push Up = 0.947 | Q Average = 0.884 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 4031 | Walltime = 443.577\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 361 | Learner Steps = 3700 | Steps = 4039 | Steps Per Second = 533.677 | Walltime = 447.097\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/40 [07:28<00:35, 11.85s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 370 | Learner Steps = 3750 | Push Down = 0.940 | Push Up = 0.940 | Q Average = 0.876 | Q Variance = 0.005 | Regularizer = 0.000 | Steps = 4092 | Walltime = 453.663\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 371 | Learner Steps = 3800 | Steps = 4098 | Steps Per Second = 659.707 | Walltime = 458.894\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [07:40<00:23, 11.84s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 380 | Learner Steps = 3833 | Push Down = 0.953 | Push Up = 0.953 | Q Average = 0.887 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 4138 | Walltime = 463.692\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 381 | Learner Steps = 3900 | Steps = 4143 | Steps Per Second = 600.903 | Walltime = 470.739\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [07:52<00:11, 11.85s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 390 | Learner Steps = 3916 | Push Down = 0.951 | Push Up = 0.950 | Q Average = 0.889 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 4197 | Walltime = 473.734\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 391 | Learner Steps = 4000 | Steps = 4205 | Steps Per Second = 582.552 | Walltime = 482.505\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [08:04<00:00, 12.10s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/eb523ebe-f20e-11ea-bb72-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:15:54.419296 140435675182976 builder_impl.py:775] Assets written to: /root/acme/eb523ebe-f20e-11ea-bb72-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:15:54.422580 140435675182976 savers.py:156] Saving checkpoint: /root/acme/eb523ebe-f20e-11ea-bb72-0242ac1c0002/checkpoints/cql_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/eb523ebe-f20e-11ea-bb72-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1866\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/push_down 0.9510462880134583\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 4439\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599596153.7351692\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/critic_loss 2.9479499062290415e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/cql_loss 0.00010191032197326422\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/walltime 482.504718542099\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/q_average 0.8847399353981018\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 503.3837490081787\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Learner/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/regularizer 7.2430819272995e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Learner/push_up 0.9509738683700562\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          Learner/q_variance 0.004217370413243771\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.9945999979972839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/walltime 482.504718542099\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      EvalLoop/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 682.6666666666666\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 4247\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch_counter 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Learner/steps 4197\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/episodes 390\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/eb523ebe-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group cql-1.-random-eps0-E...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 40 media file(s), 7 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599595652\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_201606-1599596166\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599596166\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599596166\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "_____Evaluating counts for all state action pairs_____ \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:12<00:00, 79.06it/s]\n",
            "I0908 20:16:23.585173 140179806803840 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]INFO:tensorflow:Assets written to: /root/acme/1e913d60-f210-11ea-9f4e-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:16:24.869991 140179806803840 builder_impl.py:775] Assets written to: /root/acme/1e913d60-f210-11ea-9f4e-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:16:24.873662 140179806803840 savers.py:156] Saving checkpoint: /root/acme/1e913d60-f210-11ea-9f4e-0242ac1c0002/checkpoints/cql_learner\n",
            "[Learner] Cql Loss = 0.022 | Critic Loss = 0.015 | Learner Steps = 77 | Push Down = 0.588 | Push Up = 0.581 | Q Average = 0.524 | Q Variance = 0.012 | Regularizer = 0.006 | Walltime = 8.954\n",
            "[Evalloop] Episode Length = 500 | Episode Return = 0.000 | Episodes = 1 | Learner Steps = 100 | Steps = 500 | Steps Per Second = 539.552 | Walltime = 11.341\n",
            "  2%|‚ñà                                           | 1/40 [00:15<10:03, 15.49s/it][Learner] Cql Loss = 0.015 | Critic Loss = 0.011 | Episodes = 10 | Learner Steps = 135 | Push Down = 0.688 | Push Up = 0.684 | Q Average = 0.635 | Q Variance = 0.008 | Regularizer = 0.004 | Steps = 1613 | Walltime = 19.060\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 11 | Learner Steps = 200 | Steps = 1617 | Steps Per Second = 616.696 | Walltime = 26.340\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:28<09:23, 14.82s/it][Learner] Cql Loss = 0.010 | Critic Loss = 0.006 | Episodes = 20 | Learner Steps = 207 | Push Down = 0.773 | Push Up = 0.769 | Q Average = 0.711 | Q Variance = 0.008 | Regularizer = 0.004 | Steps = 2106 | Walltime = 29.187\n",
            "[Learner] Cql Loss = 0.006 | Critic Loss = 0.004 | Episodes = 20 | Learner Steps = 298 | Push Down = 0.811 | Push Up = 0.809 | Q Average = 0.761 | Q Variance = 0.005 | Regularizer = 0.002 | Steps = 2106 | Walltime = 39.215\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 21 | Learner Steps = 300 | Steps = 2110 | Steps Per Second = 370.121 | Walltime = 39.449\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:41<08:43, 14.16s/it][Learner] Cql Loss = 0.006 | Critic Loss = 0.003 | Episodes = 30 | Learner Steps = 375 | Push Down = 0.831 | Push Up = 0.828 | Q Average = 0.790 | Q Variance = 0.003 | Regularizer = 0.004 | Steps = 2187 | Walltime = 49.279\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 31 | Learner Steps = 400 | Steps = 2190 | Steps Per Second = 555.120 | Walltime = 51.994\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [00:53<08:10, 13.63s/it][Learner] Cql Loss = 0.003 | Critic Loss = 0.001 | Episodes = 40 | Learner Steps = 454 | Push Down = 0.864 | Push Up = 0.862 | Q Average = 0.827 | Q Variance = 0.002 | Regularizer = 0.002 | Steps = 2330 | Walltime = 59.318\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 41 | Learner Steps = 500 | Steps = 2335 | Steps Per Second = 598.998 | Walltime = 64.362\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [01:06<07:45, 13.31s/it][Learner] Cql Loss = 0.003 | Critic Loss = 0.001 | Episodes = 50 | Learner Steps = 531 | Push Down = 0.902 | Push Up = 0.900 | Q Average = 0.871 | Q Variance = 0.001 | Regularizer = 0.002 | Steps = 2378 | Walltime = 69.420\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 51 | Learner Steps = 600 | Steps = 2385 | Steps Per Second = 701.489 | Walltime = 76.888\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [01:18<07:21, 13.00s/it][Learner] Cql Loss = 0.002 | Critic Loss = 0.001 | Episodes = 60 | Learner Steps = 611 | Push Down = 0.928 | Push Up = 0.927 | Q Average = 0.895 | Q Variance = 0.001 | Regularizer = 0.001 | Steps = 2418 | Walltime = 79.457\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 61 | Learner Steps = 700 | Steps = 2423 | Steps Per Second = 580.800 | Walltime = 89.453\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [01:31<07:05, 12.90s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.001 | Episodes = 70 | Learner Steps = 701 | Push Down = 0.918 | Push Up = 0.917 | Q Average = 0.880 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2573 | Walltime = 91.043\n",
            "[Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 70 | Learner Steps = 793 | Push Down = 0.938 | Push Up = 0.937 | Q Average = 0.898 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2573 | Walltime = 101.138\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 71 | Learner Steps = 800 | Steps = 2578 | Steps Per Second = 645.953 | Walltime = 101.882\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [01:43<06:50, 12.82s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 80 | Learner Steps = 868 | Push Down = 0.935 | Push Up = 0.934 | Q Average = 0.896 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2629 | Walltime = 111.193\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 81 | Learner Steps = 900 | Steps = 2633 | Steps Per Second = 598.759 | Walltime = 114.729\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [01:56<06:34, 12.73s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 90 | Learner Steps = 946 | Push Down = 0.954 | Push Up = 0.953 | Q Average = 0.913 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 2694 | Walltime = 121.305\n",
            "[Evalloop] Episode Length = 10 | Episode Return = 0.982 | Episodes = 91 | Learner Steps = 1000 | Steps = 2704 | Steps Per Second = 682.589 | Walltime = 127.221\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [02:08<06:19, 12.67s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 100 | Learner Steps = 1026 | Push Down = 0.950 | Push Up = 0.949 | Q Average = 0.907 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 2760 | Walltime = 131.396\n",
            "[Evalloop] Episode Length = 10 | Episode Return = 0.982 | Episodes = 101 | Learner Steps = 1100 | Steps = 2770 | Steps Per Second = 711.092 | Walltime = 139.282\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [02:21<06:05, 12.60s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1103 | Push Down = 0.944 | Push Up = 0.943 | Q Average = 0.908 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2826 | Walltime = 141.399\n",
            "[Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1194 | Push Down = 0.952 | Push Up = 0.951 | Q Average = 0.911 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2826 | Walltime = 151.431\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 111 | Learner Steps = 1200 | Steps = 2831 | Steps Per Second = 637.142 | Walltime = 152.074\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [02:33<05:50, 12.53s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 120 | Learner Steps = 1275 | Push Down = 0.958 | Push Up = 0.958 | Q Average = 0.920 | Q Variance = 0.001 | Regularizer = 0.000 | Steps = 2880 | Walltime = 161.497\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 121 | Learner Steps = 1300 | Steps = 2884 | Steps Per Second = 597.607 | Walltime = 164.170\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [02:45<05:34, 12.40s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 130 | Learner Steps = 1355 | Push Down = 0.947 | Push Up = 0.946 | Q Average = 0.904 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 2949 | Walltime = 171.551\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 131 | Learner Steps = 1400 | Steps = 2958 | Steps Per Second = 608.154 | Walltime = 176.441\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [02:58<05:21, 12.35s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1436 | Push Down = 0.958 | Push Up = 0.958 | Q Average = 0.912 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3010 | Walltime = 181.579\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 141 | Learner Steps = 1500 | Steps = 3015 | Steps Per Second = 627.984 | Walltime = 188.688\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [03:10<05:12, 12.50s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 150 | Learner Steps = 1510 | Push Down = 0.953 | Push Up = 0.952 | Q Average = 0.911 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3063 | Walltime = 191.653\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 151 | Learner Steps = 1600 | Steps = 3069 | Steps Per Second = 652.658 | Walltime = 201.246\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [03:22<04:56, 12.34s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 160 | Learner Steps = 1601 | Push Down = 0.943 | Push Up = 0.943 | Q Average = 0.894 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3121 | Walltime = 202.684\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 160 | Learner Steps = 1695 | Push Down = 0.948 | Push Up = 0.948 | Q Average = 0.904 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3121 | Walltime = 212.763\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 161 | Learner Steps = 1700 | Steps = 3124 | Steps Per Second = 564.966 | Walltime = 213.291\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [03:34<04:41, 12.26s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 170 | Learner Steps = 1774 | Push Down = 0.959 | Push Up = 0.959 | Q Average = 0.915 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3177 | Walltime = 222.840\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 171 | Learner Steps = 1800 | Steps = 3181 | Steps Per Second = 629.209 | Walltime = 225.721\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [03:47<04:30, 12.31s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 180 | Learner Steps = 1852 | Push Down = 0.956 | Push Up = 0.956 | Q Average = 0.913 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3221 | Walltime = 232.874\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 181 | Learner Steps = 1900 | Steps = 3230 | Steps Per Second = 731.877 | Walltime = 237.912\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [03:59<04:17, 12.26s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 190 | Learner Steps = 1935 | Push Down = 0.944 | Push Up = 0.943 | Q Average = 0.895 | Q Variance = 0.003 | Regularizer = 0.001 | Steps = 3278 | Walltime = 242.916\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 191 | Learner Steps = 2000 | Steps = 3281 | Steps Per Second = 620.215 | Walltime = 249.859\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [04:12<04:07, 12.38s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 200 | Learner Steps = 2010 | Push Down = 0.954 | Push Up = 0.954 | Q Average = 0.901 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3339 | Walltime = 252.923\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 201 | Learner Steps = 2100 | Steps = 3345 | Steps Per Second = 653.726 | Walltime = 262.427\n",
            "/content/visualization.py:111: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(17, 12))\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 21/40 [04:24<03:52, 12.23s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 210 | Learner Steps = 2101 | Push Down = 0.954 | Push Up = 0.954 | Q Average = 0.902 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3394 | Walltime = 263.878\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 210 | Learner Steps = 2193 | Push Down = 0.954 | Push Up = 0.954 | Q Average = 0.909 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3394 | Walltime = 273.933\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 211 | Learner Steps = 2200 | Steps = 3401 | Steps Per Second = 627.836 | Walltime = 274.707\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [04:36<03:40, 12.24s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 220 | Learner Steps = 2276 | Push Down = 0.948 | Push Up = 0.948 | Q Average = 0.901 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3457 | Walltime = 283.980\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 221 | Learner Steps = 2300 | Steps = 3461 | Steps Per Second = 648.345 | Walltime = 286.543\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [04:48<03:25, 12.11s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 230 | Learner Steps = 2357 | Push Down = 0.959 | Push Up = 0.959 | Q Average = 0.909 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3502 | Walltime = 294.001\n",
            "[Evalloop] Episode Length = 2 | Episode Return = 0.996 | Episodes = 231 | Learner Steps = 2400 | Steps = 3504 | Steps Per Second = 549.712 | Walltime = 298.572\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [05:00<03:13, 12.08s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 240 | Learner Steps = 2440 | Push Down = 0.948 | Push Up = 0.948 | Q Average = 0.895 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3545 | Walltime = 304.095\n",
            "[Evalloop] Episode Length = 2 | Episode Return = 0.996 | Episodes = 241 | Learner Steps = 2500 | Steps = 3547 | Steps Per Second = 472.784 | Walltime = 311.073\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [05:12<03:03, 12.24s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 250 | Learner Steps = 2515 | Push Down = 0.946 | Push Up = 0.946 | Q Average = 0.893 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3582 | Walltime = 314.206\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 251 | Learner Steps = 2600 | Steps = 3587 | Steps Per Second = 626.184 | Walltime = 323.693\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [05:25<02:53, 12.36s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 260 | Learner Steps = 2601 | Push Down = 0.960 | Push Up = 0.960 | Q Average = 0.909 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3629 | Walltime = 325.223\n",
            "[Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 260 | Learner Steps = 2690 | Push Down = 0.939 | Push Up = 0.938 | Q Average = 0.881 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3629 | Walltime = 335.263\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 261 | Learner Steps = 2700 | Steps = 3634 | Steps Per Second = 599.066 | Walltime = 336.350\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [05:38<02:45, 12.70s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 270 | Learner Steps = 2761 | Push Down = 0.949 | Push Up = 0.948 | Q Average = 0.898 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3676 | Walltime = 345.310\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 271 | Learner Steps = 2800 | Steps = 3685 | Steps Per Second = 621.634 | Walltime = 349.599\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [05:51<02:31, 12.59s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 280 | Learner Steps = 2840 | Push Down = 0.948 | Push Up = 0.947 | Q Average = 0.895 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3741 | Walltime = 355.366\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 281 | Learner Steps = 2900 | Steps = 3744 | Steps Per Second = 596.318 | Walltime = 361.841\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [06:03<02:17, 12.48s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 290 | Learner Steps = 2921 | Push Down = 0.956 | Push Up = 0.956 | Q Average = 0.906 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 3782 | Walltime = 365.471\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 291 | Learner Steps = 3000 | Steps = 3788 | Steps Per Second = 624.276 | Walltime = 374.034\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [06:15<02:04, 12.41s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 300 | Learner Steps = 3001 | Push Down = 0.951 | Push Up = 0.951 | Q Average = 0.891 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3842 | Walltime = 375.508\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 300 | Learner Steps = 3093 | Push Down = 0.947 | Push Up = 0.947 | Q Average = 0.887 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3842 | Walltime = 385.576\n",
            "[Evalloop] Episode Length = 11 | Episode Return = 0.980 | Episodes = 301 | Learner Steps = 3100 | Steps = 3853 | Steps Per Second = 667.139 | Walltime = 386.343\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [06:27<01:51, 12.37s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 310 | Learner Steps = 3174 | Push Down = 0.953 | Push Up = 0.953 | Q Average = 0.895 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3892 | Walltime = 395.584\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 311 | Learner Steps = 3200 | Steps = 3898 | Steps Per Second = 680.341 | Walltime = 398.320\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [06:39<01:37, 12.25s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 320 | Learner Steps = 3257 | Push Down = 0.954 | Push Up = 0.953 | Q Average = 0.891 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 3931 | Walltime = 405.615\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 321 | Learner Steps = 3300 | Steps = 3935 | Steps Per Second = 577.827 | Walltime = 410.241\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [06:51<01:25, 12.16s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 330 | Learner Steps = 3338 | Push Down = 0.947 | Push Up = 0.947 | Q Average = 0.887 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 3987 | Walltime = 415.718\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 331 | Learner Steps = 3400 | Steps = 3990 | Steps Per Second = 572.601 | Walltime = 422.468\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [07:05<01:15, 12.53s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 340 | Learner Steps = 3407 | Push Down = 0.948 | Push Up = 0.947 | Q Average = 0.885 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 4042 | Walltime = 425.798\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 340 | Learner Steps = 3498 | Push Down = 0.949 | Push Up = 0.949 | Q Average = 0.885 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 4042 | Walltime = 435.865\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 341 | Learner Steps = 3500 | Steps = 4048 | Steps Per Second = 669.179 | Walltime = 436.075\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 35/40 [07:17<01:02, 12.50s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 350 | Learner Steps = 3577 | Push Down = 0.947 | Push Up = 0.947 | Q Average = 0.889 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 4094 | Walltime = 445.876\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 351 | Learner Steps = 3600 | Steps = 4099 | Steps Per Second = 601.230 | Walltime = 448.426\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [07:30<00:49, 12.46s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 360 | Learner Steps = 3655 | Push Down = 0.963 | Push Up = 0.963 | Q Average = 0.898 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 4143 | Walltime = 455.933\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 361 | Learner Steps = 3700 | Steps = 4151 | Steps Per Second = 631.435 | Walltime = 460.820\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/40 [07:42<00:37, 12.43s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 370 | Learner Steps = 3735 | Push Down = 0.960 | Push Up = 0.960 | Q Average = 0.894 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 4202 | Walltime = 465.967\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 371 | Learner Steps = 3800 | Steps = 4208 | Steps Per Second = 666.062 | Walltime = 473.124\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [07:54<00:24, 12.40s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 380 | Learner Steps = 3815 | Push Down = 0.953 | Push Up = 0.953 | Q Average = 0.896 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 4246 | Walltime = 476.046\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 381 | Learner Steps = 3900 | Steps = 4251 | Steps Per Second = 699.027 | Walltime = 485.142\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [08:06<00:12, 12.29s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 390 | Learner Steps = 3901 | Push Down = 0.964 | Push Up = 0.964 | Q Average = 0.900 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 4314 | Walltime = 486.611\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 390 | Learner Steps = 3992 | Push Down = 0.946 | Push Up = 0.946 | Q Average = 0.874 | Q Variance = 0.006 | Regularizer = 0.000 | Steps = 4314 | Walltime = 496.703\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 391 | Learner Steps = 4000 | Steps = 4322 | Steps Per Second = 678.608 | Walltime = 497.541\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [08:19<00:00, 12.48s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/1e913d60-f210-11ea-9f4e-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:24:43.584009 140179806803840 builder_impl.py:775] Assets written to: /root/acme/1e913d60-f210-11ea-9f4e-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:24:43.588109 140179806803840 savers.py:156] Saving checkpoint: /root/acme/1e913d60-f210-11ea-9f4e-0242ac1c0002/checkpoints/cql_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/1e913d60-f210-11ea-9f4e-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 2016\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 517.118509054184\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/cql_loss 0.00013643436250276864\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 4439\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Learner/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599596682.874341\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/critic_loss 3.128057869616896e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          Learner/q_variance 0.003632540116086602\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/q_average 0.8880932927131653\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/walltime 497.54114508628845\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/regularizer 0.00010515376925468445\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Learner/push_up 0.9492290019989014\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/push_down 0.9493341445922852\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      EvalLoop/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.9945999979972839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/walltime 497.54114508628845\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 4364\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 665.7625396825397\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch_counter 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/episodes 390\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Learner/steps 4314\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/1e913d60-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group cql-1.-random-eps0-E...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 40 media file(s), 7 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599596166\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_202454-1599596694\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599596694\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599596694\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "_____Evaluating counts for all state action pairs_____ \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:12<00:00, 81.05it/s]\n",
            "I0908 20:25:11.343938 140597652969344 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]INFO:tensorflow:Assets written to: /root/acme/5957d868-f211-11ea-8dea-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:25:12.609526 140597652969344 builder_impl.py:775] Assets written to: /root/acme/5957d868-f211-11ea-8dea-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:25:12.612811 140597652969344 savers.py:156] Saving checkpoint: /root/acme/5957d868-f211-11ea-8dea-0242ac1c0002/checkpoints/cql_learner\n",
            "[Learner] Cql Loss = 0.023 | Critic Loss = 0.016 | Learner Steps = 80 | Push Down = 0.601 | Push Up = 0.594 | Q Average = 0.537 | Q Variance = 0.012 | Regularizer = 0.007 | Walltime = 8.953\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 1 | Learner Steps = 100 | Steps = 4 | Steps Per Second = 16.366 | Walltime = 11.067\n",
            "  2%|‚ñà                                           | 1/40 [00:13<08:50, 13.59s/it][Learner] Cql Loss = 0.019 | Critic Loss = 0.009 | Episodes = 10 | Learner Steps = 153 | Push Down = 0.674 | Push Up = 0.664 | Q Average = 0.618 | Q Variance = 0.008 | Regularizer = 0.010 | Steps = 382 | Walltime = 18.960\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 11 | Learner Steps = 200 | Steps = 386 | Steps Per Second = 645.253 | Walltime = 24.042\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:26<08:23, 13.24s/it][Learner] Cql Loss = 0.008 | Critic Loss = 0.006 | Episodes = 20 | Learner Steps = 231 | Push Down = 0.768 | Push Up = 0.765 | Q Average = 0.716 | Q Variance = 0.006 | Regularizer = 0.003 | Steps = 551 | Walltime = 29.002\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 21 | Learner Steps = 300 | Steps = 555 | Steps Per Second = 647.969 | Walltime = 36.332\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:38<07:58, 12.93s/it][Learner] Cql Loss = 0.006 | Critic Loss = 0.004 | Episodes = 30 | Learner Steps = 311 | Push Down = 0.825 | Push Up = 0.824 | Q Average = 0.787 | Q Variance = 0.002 | Regularizer = 0.002 | Steps = 620 | Walltime = 39.029\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 31 | Learner Steps = 400 | Steps = 623 | Steps Per Second = 605.210 | Walltime = 48.526\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [00:50<07:35, 12.64s/it][Learner] Cql Loss = 0.004 | Critic Loss = 0.003 | Episodes = 40 | Learner Steps = 401 | Push Down = 0.836 | Push Up = 0.835 | Q Average = 0.795 | Q Variance = 0.003 | Regularizer = 0.001 | Steps = 679 | Walltime = 49.937\n",
            "[Learner] Cql Loss = 0.003 | Critic Loss = 0.001 | Episodes = 40 | Learner Steps = 494 | Push Down = 0.903 | Push Up = 0.901 | Q Average = 0.867 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 679 | Walltime = 59.964\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 41 | Learner Steps = 500 | Steps = 684 | Steps Per Second = 640.469 | Walltime = 60.587\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [01:02<07:19, 12.55s/it][Learner] Cql Loss = 0.003 | Critic Loss = 0.001 | Episodes = 50 | Learner Steps = 574 | Push Down = 0.908 | Push Up = 0.906 | Q Average = 0.880 | Q Variance = 0.001 | Regularizer = 0.002 | Steps = 730 | Walltime = 70.058\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 51 | Learner Steps = 600 | Steps = 737 | Steps Per Second = 709.713 | Walltime = 72.749\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [01:14<06:59, 12.35s/it][Learner] Cql Loss = 0.002 | Critic Loss = 0.001 | Episodes = 60 | Learner Steps = 658 | Push Down = 0.917 | Push Up = 0.916 | Q Average = 0.883 | Q Variance = 0.001 | Regularizer = 0.001 | Steps = 775 | Walltime = 80.092\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 61 | Learner Steps = 700 | Steps = 780 | Steps Per Second = 665.045 | Walltime = 84.513\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [01:26<06:41, 12.18s/it][Learner] Cql Loss = 0.002 | Critic Loss = 0.000 | Episodes = 70 | Learner Steps = 740 | Push Down = 0.925 | Push Up = 0.923 | Q Average = 0.889 | Q Variance = 0.002 | Regularizer = 0.002 | Steps = 824 | Walltime = 90.182\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 71 | Learner Steps = 800 | Steps = 829 | Steps Per Second = 567.411 | Walltime = 96.983\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [01:39<06:36, 12.40s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.001 | Episodes = 80 | Learner Steps = 812 | Push Down = 0.947 | Push Up = 0.946 | Q Average = 0.912 | Q Variance = 0.001 | Regularizer = 0.001 | Steps = 885 | Walltime = 100.205\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 81 | Learner Steps = 900 | Steps = 889 | Steps Per Second = 656.026 | Walltime = 109.622\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [01:51<06:22, 12.34s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 90 | Learner Steps = 901 | Push Down = 0.932 | Push Up = 0.931 | Q Average = 0.888 | Q Variance = 0.003 | Regularizer = 0.001 | Steps = 952 | Walltime = 111.060\n",
            "[Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 90 | Learner Steps = 996 | Push Down = 0.939 | Push Up = 0.939 | Q Average = 0.901 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 952 | Walltime = 121.097\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 91 | Learner Steps = 1000 | Steps = 960 | Steps Per Second = 571.733 | Walltime = 121.514\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [02:03<06:06, 12.23s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 100 | Learner Steps = 1078 | Push Down = 0.960 | Push Up = 0.959 | Q Average = 0.919 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 1020 | Walltime = 131.198\n",
            "[Evalloop] Episode Length = 10 | Episode Return = 0.982 | Episodes = 101 | Learner Steps = 1100 | Steps = 1030 | Steps Per Second = 701.623 | Walltime = 133.576\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [02:15<05:56, 12.30s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1154 | Push Down = 0.943 | Push Up = 0.942 | Q Average = 0.901 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 1086 | Walltime = 141.249\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 111 | Learner Steps = 1200 | Steps = 1091 | Steps Per Second = 604.175 | Walltime = 146.272\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [02:27<05:43, 12.28s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 120 | Learner Steps = 1235 | Push Down = 0.962 | Push Up = 0.961 | Q Average = 0.916 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 1140 | Walltime = 151.322\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 121 | Learner Steps = 1300 | Steps = 1144 | Steps Per Second = 598.033 | Walltime = 158.192\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [02:39<05:28, 12.17s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 130 | Learner Steps = 1316 | Push Down = 0.950 | Push Up = 0.949 | Q Average = 0.909 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 1204 | Walltime = 161.334\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 131 | Learner Steps = 1400 | Steps = 1211 | Steps Per Second = 638.236 | Walltime = 170.460\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [02:52<05:17, 12.20s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1401 | Push Down = 0.955 | Push Up = 0.954 | Q Average = 0.911 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 1261 | Walltime = 171.939\n",
            "[Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1494 | Push Down = 0.956 | Push Up = 0.955 | Q Average = 0.915 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 1261 | Walltime = 181.952\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 141 | Learner Steps = 1500 | Steps = 1264 | Steps Per Second = 575.561 | Walltime = 182.602\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [03:04<05:08, 12.35s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 150 | Learner Steps = 1570 | Push Down = 0.957 | Push Up = 0.957 | Q Average = 0.916 | Q Variance = 0.001 | Regularizer = 0.000 | Steps = 1316 | Walltime = 191.981\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 151 | Learner Steps = 1600 | Steps = 1323 | Steps Per Second = 626.416 | Walltime = 195.269\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [03:16<04:54, 12.27s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 160 | Learner Steps = 1650 | Push Down = 0.962 | Push Up = 0.961 | Q Average = 0.919 | Q Variance = 0.002 | Regularizer = 0.001 | Steps = 1369 | Walltime = 201.981\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 161 | Learner Steps = 1700 | Steps = 1372 | Steps Per Second = 588.647 | Walltime = 207.474\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [03:29<04:41, 12.25s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 170 | Learner Steps = 1730 | Push Down = 0.956 | Push Up = 0.956 | Q Average = 0.906 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 1421 | Walltime = 212.072\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 171 | Learner Steps = 1800 | Steps = 1425 | Steps Per Second = 611.905 | Walltime = 219.662\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [03:41<04:29, 12.24s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 180 | Learner Steps = 1810 | Push Down = 0.954 | Push Up = 0.954 | Q Average = 0.905 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 1466 | Walltime = 222.086\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 181 | Learner Steps = 1900 | Steps = 1473 | Steps Per Second = 646.571 | Walltime = 231.951\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [03:53<04:17, 12.25s/it][Learner] Cql Loss = 0.001 | Critic Loss = 0.000 | Episodes = 190 | Learner Steps = 1901 | Push Down = 0.950 | Push Up = 0.950 | Q Average = 0.901 | Q Variance = 0.003 | Regularizer = 0.001 | Steps = 1516 | Walltime = 233.393\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 190 | Learner Steps = 1994 | Push Down = 0.954 | Push Up = 0.953 | Q Average = 0.909 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 1516 | Walltime = 243.457\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 191 | Learner Steps = 2000 | Steps = 1519 | Steps Per Second = 613.053 | Walltime = 244.090\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [04:06<04:08, 12.45s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 200 | Learner Steps = 2068 | Push Down = 0.953 | Push Up = 0.952 | Q Average = 0.901 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 1577 | Walltime = 253.517\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 201 | Learner Steps = 2100 | Steps = 1583 | Steps Per Second = 683.334 | Walltime = 256.975\n",
            "/content/visualization.py:111: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(17, 12))\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 21/40 [04:18<03:54, 12.35s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 210 | Learner Steps = 2148 | Push Down = 0.940 | Push Up = 0.940 | Q Average = 0.890 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 1627 | Walltime = 263.559\n",
            "[Evalloop] Episode Length = 11 | Episode Return = 0.980 | Episodes = 211 | Learner Steps = 2200 | Steps = 1638 | Steps Per Second = 733.410 | Walltime = 269.184\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [04:30<03:41, 12.31s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 220 | Learner Steps = 2227 | Push Down = 0.956 | Push Up = 0.956 | Q Average = 0.908 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 1697 | Walltime = 273.626\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 221 | Learner Steps = 2300 | Steps = 1701 | Steps Per Second = 616.968 | Walltime = 281.446\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [04:43<03:28, 12.28s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 230 | Learner Steps = 2308 | Push Down = 0.954 | Push Up = 0.954 | Q Average = 0.906 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 1742 | Walltime = 283.637\n",
            "[Evalloop] Episode Length = 2 | Episode Return = 0.996 | Episodes = 231 | Learner Steps = 2400 | Steps = 1744 | Steps Per Second = 528.583 | Walltime = 293.548\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [04:55<03:15, 12.23s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 240 | Learner Steps = 2401 | Push Down = 0.960 | Push Up = 0.959 | Q Average = 0.909 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 1787 | Walltime = 294.954\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 240 | Learner Steps = 2493 | Push Down = 0.958 | Push Up = 0.958 | Q Average = 0.905 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 1787 | Walltime = 304.989\n",
            "[Evalloop] Episode Length = 2 | Episode Return = 0.996 | Episodes = 241 | Learner Steps = 2500 | Steps = 1789 | Steps Per Second = 580.446 | Walltime = 305.717\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [05:07<03:03, 12.23s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 250 | Learner Steps = 2574 | Push Down = 0.946 | Push Up = 0.946 | Q Average = 0.894 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 1828 | Walltime = 315.024\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 251 | Learner Steps = 2600 | Steps = 1833 | Steps Per Second = 557.383 | Walltime = 317.710\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [05:19<02:50, 12.15s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 260 | Learner Steps = 2656 | Push Down = 0.957 | Push Up = 0.957 | Q Average = 0.907 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 1878 | Walltime = 325.084\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 261 | Learner Steps = 2700 | Steps = 1883 | Steps Per Second = 571.322 | Walltime = 329.893\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [05:32<02:41, 12.45s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 270 | Learner Steps = 2727 | Push Down = 0.950 | Push Up = 0.950 | Q Average = 0.895 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 1924 | Walltime = 335.118\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 271 | Learner Steps = 2800 | Steps = 1933 | Steps Per Second = 653.251 | Walltime = 343.001\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [05:44<02:28, 12.36s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 280 | Learner Steps = 2807 | Push Down = 0.955 | Push Up = 0.955 | Q Average = 0.893 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 1981 | Walltime = 345.155\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 281 | Learner Steps = 2900 | Steps = 1984 | Steps Per Second = 600.129 | Walltime = 355.121\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [05:56<02:15, 12.27s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 290 | Learner Steps = 2901 | Push Down = 0.962 | Push Up = 0.962 | Q Average = 0.907 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 2020 | Walltime = 356.523\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 290 | Learner Steps = 2995 | Push Down = 0.957 | Push Up = 0.957 | Q Average = 0.904 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2020 | Walltime = 366.531\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 291 | Learner Steps = 3000 | Steps = 2028 | Steps Per Second = 565.442 | Walltime = 367.084\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [06:08<02:02, 12.20s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 300 | Learner Steps = 3074 | Push Down = 0.949 | Push Up = 0.949 | Q Average = 0.898 | Q Variance = 0.002 | Regularizer = 0.000 | Steps = 2084 | Walltime = 376.538\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 301 | Learner Steps = 3100 | Steps = 2093 | Steps Per Second = 349.985 | Walltime = 379.334\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [06:21<01:50, 12.22s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 310 | Learner Steps = 3152 | Push Down = 0.948 | Push Up = 0.948 | Q Average = 0.887 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 2136 | Walltime = 386.613\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 311 | Learner Steps = 3200 | Steps = 2144 | Steps Per Second = 669.896 | Walltime = 391.907\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [06:33<01:38, 12.33s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 320 | Learner Steps = 3230 | Push Down = 0.961 | Push Up = 0.961 | Q Average = 0.896 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 2175 | Walltime = 396.619\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 321 | Learner Steps = 3300 | Steps = 2179 | Steps Per Second = 544.609 | Walltime = 404.712\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [06:46<01:27, 12.51s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 330 | Learner Steps = 3303 | Push Down = 0.962 | Push Up = 0.962 | Q Average = 0.900 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2233 | Walltime = 406.625\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 330 | Learner Steps = 3389 | Push Down = 0.947 | Push Up = 0.947 | Q Average = 0.891 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2233 | Walltime = 416.635\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 331 | Learner Steps = 3400 | Steps = 2236 | Steps Per Second = 538.583 | Walltime = 417.851\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [07:00<01:17, 13.00s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 340 | Learner Steps = 3458 | Push Down = 0.955 | Push Up = 0.955 | Q Average = 0.902 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2290 | Walltime = 426.644\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 341 | Learner Steps = 3500 | Steps = 2296 | Steps Per Second = 686.129 | Walltime = 431.188\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 35/40 [07:12<01:03, 12.74s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 350 | Learner Steps = 3538 | Push Down = 0.948 | Push Up = 0.948 | Q Average = 0.887 | Q Variance = 0.004 | Regularizer = 0.000 | Steps = 2338 | Walltime = 436.691\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 351 | Learner Steps = 3600 | Steps = 2343 | Steps Per Second = 653.542 | Walltime = 443.456\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [07:25<00:50, 12.60s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 360 | Learner Steps = 3617 | Push Down = 0.953 | Push Up = 0.953 | Q Average = 0.894 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2390 | Walltime = 446.691\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 361 | Learner Steps = 3700 | Steps = 2398 | Steps Per Second = 610.280 | Walltime = 455.805\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/40 [07:37<00:37, 12.56s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 370 | Learner Steps = 3701 | Push Down = 0.946 | Push Up = 0.946 | Q Average = 0.882 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2447 | Walltime = 457.349\n",
            "[Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 370 | Learner Steps = 3792 | Push Down = 0.947 | Push Up = 0.947 | Q Average = 0.883 | Q Variance = 0.005 | Regularizer = 0.000 | Steps = 2447 | Walltime = 467.395\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 371 | Learner Steps = 3800 | Steps = 2453 | Steps Per Second = 653.930 | Walltime = 468.273\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [07:49<00:25, 12.50s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 380 | Learner Steps = 3872 | Push Down = 0.952 | Push Up = 0.952 | Q Average = 0.889 | Q Variance = 0.003 | Regularizer = 0.000 | Steps = 2491 | Walltime = 477.469\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 381 | Learner Steps = 3900 | Steps = 2496 | Steps Per Second = 620.184 | Walltime = 480.498\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [08:02<00:12, 12.43s/it][Learner] Cql Loss = 0.000 | Critic Loss = 0.000 | Episodes = 390 | Learner Steps = 3951 | Push Down = 0.946 | Push Up = 0.946 | Q Average = 0.879 | Q Variance = 0.005 | Regularizer = 0.000 | Steps = 2548 | Walltime = 487.565\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 391 | Learner Steps = 4000 | Steps = 2556 | Steps Per Second = 676.010 | Walltime = 492.949\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [08:14<00:00, 12.37s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/5957d868-f211-11ea-8dea-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:33:26.726134 140597652969344 builder_impl.py:775] Assets written to: /root/acme/5957d868-f211-11ea-8dea-0242ac1c0002/snapshots/network/assets\n",
            "I0908 20:33:26.729865 140597652969344 savers.py:156] Saving checkpoint: /root/acme/5957d868-f211-11ea-8dea-0242ac1c0002/checkpoints/cql_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/5957d868-f211-11ea-8dea-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 2163\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/q_average 0.8880605697631836\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Learner/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 4439\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Learner/push_up 0.95437091588974\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 512.1248879432678\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/critic_loss 3.706500501721166e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/push_down 0.9544580578804016\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/walltime 492.9485650062561\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          Learner/q_variance 0.00419181864708662\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/regularizer 8.720345795154572e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599597206.014791\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/cql_loss 0.00012426846660673618\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/walltime 492.9485650062561\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 721.0011460004584\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 2600\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.9945999979972839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      EvalLoop/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch_counter 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Learner/steps 2548\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/episodes 390\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/5957d868-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group cql-1.-random-eps0-E...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 40 media file(s), 7 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599596694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmsDu3Q993HI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed390d2e-d254-44c4-d5c8-70ab77e6ce03"
      },
      "source": [
        "for i in range(3):\n",
        "  !python run_offline_bc.py --dataset_dir=$dataset_dir \\\n",
        "                          --environment_name=$environment_name \\\n",
        "                            --epochs=40 \\\n",
        "                            --logs_tag='bc-eps0-ng-Empty-Random-6x6-1step' \\\n",
        "                            --max_eval_episode_len=500 \\\n",
        "                            --epsilon=0.05 \\\n",
        "                            --n_step_returns=1 \\\n",
        "                            --learning_rate=1e-4 \\\n",
        "                            --wandb=True \\\n",
        "                            --wandb_id=''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_134652-1599572812\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599572812\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599572812\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "I0908 13:46:55.744448 139891056117632 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]INFO:tensorflow:Assets written to: /root/acme/bfb56996-f1d9-11ea-afae-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:46:58.558674 139891056117632 builder_impl.py:775] Assets written to: /root/acme/bfb56996-f1d9-11ea-afae-0242ac1c0002/snapshots/network/assets\n",
            "[Learner] Gradient Norm = 3.448 | Loss = 1.093 | Steps = 1\n",
            "  2%|‚ñà                                           | 1/40 [00:04<02:54,  4.48s/it][Learner] Episodes = 10 | Gradient Norm = 0.576 | Loss = 0.778 | Steps = 949\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:07<02:30,  3.96s/it][Learner] Episodes = 20 | Gradient Norm = 0.680 | Loss = 0.789 | Steps = 2422\n",
            "[Evalloop] Episode Length = 153 | Episode Return = 0.725 | Episodes = 27 | Steps = 3441 | Steps Per Second = 821.239\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:09<02:10,  3.52s/it][Learner] Episodes = 30 | Gradient Norm = 0.896 | Loss = 0.677 | Steps = 3709\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [00:13<02:14,  3.74s/it][Learner] Episodes = 40 | Gradient Norm = 0.774 | Loss = 0.696 | Steps = 6351\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [00:17<02:04,  3.54s/it][Learner] Episodes = 50 | Gradient Norm = 1.355 | Loss = 0.752 | Steps = 8004\n",
            "[Evalloop] Episode Length = 181 | Episode Return = 0.674 | Episodes = 60 | Steps = 9179 | Steps Per Second = 804.335\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [00:19<01:49,  3.23s/it][Learner] Episodes = 60 | Gradient Norm = 0.858 | Loss = 0.657 | Steps = 9180\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [00:21<01:35,  2.88s/it][Learner] Episodes = 70 | Gradient Norm = 2.277 | Loss = 0.611 | Steps = 10048\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [00:23<01:18,  2.47s/it][Learner] Episodes = 80 | Gradient Norm = 1.824 | Loss = 0.562 | Steps = 10661\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [00:24<01:07,  2.17s/it][Learner] Episodes = 90 | Gradient Norm = 2.295 | Loss = 0.547 | Steps = 11267\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [00:26<00:59,  1.97s/it][Learner] Episodes = 100 | Gradient Norm = 1.642 | Loss = 0.487 | Steps = 11951\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [00:27<00:50,  1.75s/it][Learner] Episodes = 110 | Gradient Norm = 2.267 | Loss = 0.507 | Steps = 12383\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [00:28<00:44,  1.60s/it][Learner] Episodes = 120 | Gradient Norm = 1.668 | Loss = 0.469 | Steps = 12835\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [00:29<00:37,  1.40s/it][Learner] Episodes = 130 | Gradient Norm = 1.741 | Loss = 0.460 | Steps = 13136\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 131 | Steps = 13227 | Steps Per Second = 461.958\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [00:30<00:35,  1.37s/it][Learner] Episodes = 140 | Gradient Norm = 2.659 | Loss = 0.373 | Steps = 13547\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [00:31<00:31,  1.28s/it][Learner] Episodes = 150 | Gradient Norm = 2.000 | Loss = 0.309 | Steps = 13892\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [00:32<00:27,  1.13s/it][Learner] Episodes = 160 | Gradient Norm = 2.508 | Loss = 0.286 | Steps = 14154\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [00:33<00:24,  1.09s/it][Learner] Episodes = 170 | Gradient Norm = 1.832 | Loss = 0.354 | Steps = 14447\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [00:34<00:23,  1.05s/it][Learner] Episodes = 180 | Gradient Norm = 3.402 | Loss = 0.262 | Steps = 14746\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [00:36<00:24,  1.17s/it][Learner] Episodes = 190 | Gradient Norm = 2.259 | Loss = 0.274 | Steps = 15149\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [00:36<00:21,  1.07s/it][Learner] Episodes = 200 | Gradient Norm = 2.205 | Loss = 0.199 | Steps = 15431\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [00:38<00:15,  1.15it/s][Learner] Episodes = 220 | Gradient Norm = 1.575 | Loss = 0.245 | Steps = 15703\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [00:39<00:16,  1.05it/s][Learner] Episodes = 230 | Gradient Norm = 1.765 | Loss = 0.206 | Steps = 15932\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 231 | Steps = 16037 | Steps Per Second = 550.928\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [00:40<00:14,  1.07it/s][Learner] Episodes = 240 | Gradient Norm = 3.889 | Loss = 0.132 | Steps = 16146\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [00:41<00:13,  1.08it/s][Learner] Episodes = 250 | Gradient Norm = 4.315 | Loss = 0.139 | Steps = 16311\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [00:42<00:12,  1.08it/s][Learner] Episodes = 260 | Gradient Norm = 2.822 | Loss = 0.151 | Steps = 16469\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [00:43<00:13,  1.06s/it][Learner] Episodes = 270 | Gradient Norm = 1.932 | Loss = 0.190 | Steps = 16725\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [00:44<00:11,  1.06it/s][Learner] Episodes = 280 | Gradient Norm = 1.770 | Loss = 0.084 | Steps = 16929\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [00:45<00:10,  1.05it/s][Learner] Episodes = 290 | Gradient Norm = 1.998 | Loss = 0.088 | Steps = 17089\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [00:46<00:09,  1.03it/s][Learner] Episodes = 300 | Gradient Norm = 5.582 | Loss = 0.165 | Steps = 17260\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [00:47<00:08,  1.05it/s][Learner] Episodes = 310 | Gradient Norm = 1.947 | Loss = 0.078 | Steps = 17418\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [00:48<00:07,  1.04it/s][Learner] Episodes = 320 | Gradient Norm = 1.342 | Loss = 0.072 | Steps = 17579\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [00:49<00:06,  1.03it/s][Learner] Episodes = 330 | Gradient Norm = 1.673 | Loss = 0.073 | Steps = 17744\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [00:49<00:05,  1.04it/s][Learner] Episodes = 340 | Gradient Norm = 1.048 | Loss = 0.051 | Steps = 17893\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 341 | Steps = 17923 | Steps Per Second = 492.077\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 35/40 [00:50<00:04,  1.03it/s][Learner] Episodes = 350 | Gradient Norm = 1.700 | Loss = 0.059 | Steps = 18036\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [00:52<00:03,  1.00it/s][Learner] Episodes = 360 | Gradient Norm = 3.676 | Loss = 0.127 | Steps = 18206\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/40 [00:52<00:02,  1.03it/s][Learner] Episodes = 370 | Gradient Norm = 2.979 | Loss = 0.059 | Steps = 18353\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [00:53<00:01,  1.03it/s][Learner] Episodes = 380 | Gradient Norm = 0.900 | Loss = 0.023 | Steps = 18508\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [00:54<00:00,  1.02it/s][Learner] Episodes = 390 | Gradient Norm = 2.223 | Loss = 0.037 | Steps = 18667\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:55<00:00,  1.40s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/bfb56996-f1d9-11ea-afae-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:47:52.551865 139891056117632 builder_impl.py:775] Assets written to: /root/acme/bfb56996-f1d9-11ea-afae-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:47:52.557755 139891056117632 savers.py:156] Saving checkpoint: /root/acme/bfb56996-f1d9-11ea-afae-0242ac1c0002/checkpoints/bc_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/bfb56996-f1d9-11ea-afae-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1463\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 437.24826687516287\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 60.53175354003906\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.9855999946594238\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599572872.3592997\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 18728\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 399\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/bfb56996-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group bc-eps0-ng-Empty-Ran...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599572812\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_134801-1599572881\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599572881\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599572881\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "I0908 13:48:04.618753 140053955598208 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]INFO:tensorflow:Assets written to: /root/acme/e8dd7c50-f1d9-11ea-bbf3-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:48:07.413777 140053955598208 builder_impl.py:775] Assets written to: /root/acme/e8dd7c50-f1d9-11ea-bbf3-0242ac1c0002/snapshots/network/assets\n",
            "[Learner] Gradient Norm = 3.448 | Loss = 1.093 | Steps = 1\n",
            "  2%|‚ñà                                           | 1/40 [00:04<02:48,  4.32s/it][Learner] Episodes = 10 | Gradient Norm = 1.256 | Loss = 0.818 | Steps = 949\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:07<02:25,  3.84s/it][Learner] Episodes = 20 | Gradient Norm = 1.043 | Loss = 0.770 | Steps = 2422\n",
            "[Evalloop] Episode Length = 121 | Episode Return = 0.782 | Episodes = 28 | Steps = 3562 | Steps Per Second = 764.180\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:09<02:07,  3.43s/it][Learner] Episodes = 30 | Gradient Norm = 0.721 | Loss = 0.706 | Steps = 3709\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [00:13<02:12,  3.69s/it][Learner] Episodes = 40 | Gradient Norm = 0.782 | Loss = 0.637 | Steps = 6351\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [00:16<02:02,  3.49s/it][Learner] Episodes = 50 | Gradient Norm = 0.937 | Loss = 0.685 | Steps = 8004\n",
            "[Evalloop] Episode Length = 154 | Episode Return = 0.723 | Episodes = 59 | Steps = 9348 | Steps Per Second = 772.740\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [00:19<01:50,  3.25s/it][Learner] Episodes = 60 | Gradient Norm = 1.211 | Loss = 0.710 | Steps = 9368\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [00:21<01:35,  2.89s/it][Learner] Episodes = 70 | Gradient Norm = 0.856 | Loss = 0.619 | Steps = 10404\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [00:23<01:20,  2.52s/it][Learner] Episodes = 80 | Gradient Norm = 0.980 | Loss = 0.624 | Steps = 11168\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [00:24<01:07,  2.18s/it][Learner] Episodes = 90 | Gradient Norm = 2.525 | Loss = 0.563 | Steps = 11619\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [00:26<00:58,  1.95s/it][Learner] Episodes = 100 | Gradient Norm = 2.524 | Loss = 0.590 | Steps = 12174\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [00:26<00:46,  1.62s/it][Learner] Episodes = 110 | Gradient Norm = 1.126 | Loss = 0.449 | Steps = 12441\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [00:28<00:43,  1.54s/it][Learner] Episodes = 120 | Gradient Norm = 1.659 | Loss = 0.408 | Steps = 12826\n",
            "[Evalloop] Episode Length = 115 | Episode Return = 0.793 | Episodes = 129 | Steps = 13286 | Steps Per Second = 781.330\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [00:29<00:39,  1.46s/it][Learner] Episodes = 130 | Gradient Norm = 1.596 | Loss = 0.382 | Steps = 13291\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [00:30<00:36,  1.42s/it][Learner] Episodes = 140 | Gradient Norm = 3.861 | Loss = 0.378 | Steps = 13789\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [00:31<00:33,  1.33s/it][Learner] Episodes = 150 | Gradient Norm = 2.411 | Loss = 0.406 | Steps = 14190\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [00:32<00:29,  1.21s/it][Learner] Episodes = 160 | Gradient Norm = 4.118 | Loss = 0.381 | Steps = 14467\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [00:34<00:29,  1.30s/it][Learner] Episodes = 170 | Gradient Norm = 2.028 | Loss = 0.305 | Steps = 14974\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [00:35<00:26,  1.20s/it][Learner] Episodes = 180 | Gradient Norm = 3.718 | Loss = 0.295 | Steps = 15235\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [00:36<00:25,  1.20s/it][Learner] Episodes = 190 | Gradient Norm = 1.486 | Loss = 0.227 | Steps = 15583\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [00:37<00:21,  1.08s/it][Learner] Episodes = 200 | Gradient Norm = 2.317 | Loss = 0.317 | Steps = 15858\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 21/40 [00:38<00:19,  1.05s/it][Learner] Episodes = 210 | Gradient Norm = 1.596 | Loss = 0.182 | Steps = 16134\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [00:38<00:16,  1.10it/s][Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 221 | Steps = 16331 | Steps Per Second = 477.046\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [00:40<00:16,  1.03it/s][Learner] Episodes = 230 | Gradient Norm = 3.094 | Loss = 0.204 | Steps = 16488\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [00:40<00:14,  1.09it/s][Learner] Episodes = 240 | Gradient Norm = 2.217 | Loss = 0.158 | Steps = 16718\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [00:41<00:13,  1.11it/s][Learner] Episodes = 250 | Gradient Norm = 1.358 | Loss = 0.159 | Steps = 16877\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [00:42<00:12,  1.09it/s][Learner] Episodes = 260 | Gradient Norm = 2.557 | Loss = 0.127 | Steps = 17029\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [00:43<00:12,  1.04it/s][Learner] Episodes = 270 | Gradient Norm = 1.260 | Loss = 0.084 | Steps = 17211\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [00:44<00:11,  1.07it/s][Learner] Episodes = 280 | Gradient Norm = 1.463 | Loss = 0.133 | Steps = 17368\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [00:45<00:10,  1.04it/s][Learner] Episodes = 290 | Gradient Norm = 1.085 | Loss = 0.057 | Steps = 17534\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [00:46<00:09,  1.00it/s][Learner] Episodes = 300 | Gradient Norm = 2.204 | Loss = 0.097 | Steps = 17742\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [00:47<00:08,  1.05it/s][Learner] Episodes = 310 | Gradient Norm = 1.836 | Loss = 0.093 | Steps = 17903\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [00:48<00:07,  1.05it/s][Learner] Episodes = 320 | Gradient Norm = 3.609 | Loss = 0.109 | Steps = 18075\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [00:49<00:06,  1.05it/s][Learner] Episodes = 330 | Gradient Norm = 1.077 | Loss = 0.059 | Steps = 18239\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 331 | Steps = 18254 | Steps Per Second = 497.870\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [00:50<00:05,  1.05it/s][Learner] Episodes = 340 | Gradient Norm = 1.681 | Loss = 0.077 | Steps = 18393\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [00:52<00:03,  1.04it/s][Learner] Episodes = 360 | Gradient Norm = 1.074 | Loss = 0.042 | Steps = 18597\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/40 [00:53<00:02,  1.06it/s][Learner] Episodes = 370 | Gradient Norm = 1.662 | Loss = 0.032 | Steps = 18758\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [00:54<00:01,  1.05it/s][Learner] Episodes = 380 | Gradient Norm = 2.046 | Loss = 0.048 | Steps = 18914\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [00:55<00:00,  1.05it/s][Learner] Episodes = 390 | Gradient Norm = 1.826 | Loss = 0.039 | Steps = 19076\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:56<00:00,  1.40s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/e8dd7c50-f1d9-11ea-bbf3-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:49:01.571502 140053955598208 builder_impl.py:775] Assets written to: /root/acme/e8dd7c50-f1d9-11ea-bbf3-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:49:01.577011 140053955598208 savers.py:156] Saving checkpoint: /root/acme/e8dd7c50-f1d9-11ea-bbf3-0242ac1c0002/checkpoints/bc_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/e8dd7c50-f1d9-11ea-bbf3-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1558\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 19189\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.9855999946594238\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 60.603790044784546\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 544.2112331122175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599572941.47001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 399\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/e8dd7c50-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group bc-eps0-ng-Empty-Ran...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599572881\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_134909-1599572949\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599572949\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599572949\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "I0908 13:49:13.478547 140374620792704 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]INFO:tensorflow:Assets written to: /root/acme/11e878de-f1da-11ea-9ee7-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:49:16.378390 140374620792704 builder_impl.py:775] Assets written to: /root/acme/11e878de-f1da-11ea-9ee7-0242ac1c0002/snapshots/network/assets\n",
            "[Learner] Gradient Norm = 3.448 | Loss = 1.093 | Steps = 1\n",
            "  2%|‚ñà                                           | 1/40 [00:04<02:55,  4.49s/it][Learner] Episodes = 10 | Gradient Norm = 0.895 | Loss = 0.887 | Steps = 949\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:07<02:30,  3.96s/it][Learner] Episodes = 20 | Gradient Norm = 1.563 | Loss = 0.686 | Steps = 2422\n",
            "[Evalloop] Episode Length = 153 | Episode Return = 0.725 | Episodes = 27 | Steps = 3441 | Steps Per Second = 779.011\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:09<02:09,  3.51s/it][Learner] Episodes = 30 | Gradient Norm = 1.573 | Loss = 0.713 | Steps = 3709\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [00:13<02:14,  3.73s/it][Learner] Episodes = 40 | Gradient Norm = 0.812 | Loss = 0.634 | Steps = 6351\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [00:16<02:02,  3.49s/it][Learner] Episodes = 50 | Gradient Norm = 0.843 | Loss = 0.673 | Steps = 8004\n",
            "[Evalloop] Episode Length = 154 | Episode Return = 0.723 | Episodes = 59 | Steps = 9348 | Steps Per Second = 799.539\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [00:19<01:50,  3.25s/it][Learner] Episodes = 60 | Gradient Norm = 1.240 | Loss = 0.664 | Steps = 9368\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [00:21<01:34,  2.86s/it][Learner] Episodes = 70 | Gradient Norm = 2.178 | Loss = 0.613 | Steps = 10323\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [00:23<01:23,  2.60s/it][Learner] Episodes = 80 | Gradient Norm = 1.115 | Loss = 0.696 | Steps = 11094\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [00:24<01:07,  2.18s/it][Learner] Episodes = 90 | Gradient Norm = 1.552 | Loss = 0.555 | Steps = 11517\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [00:25<00:57,  1.90s/it][Learner] Episodes = 100 | Gradient Norm = 1.258 | Loss = 0.443 | Steps = 11951\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [00:27<00:48,  1.67s/it][Learner] Episodes = 110 | Gradient Norm = 1.771 | Loss = 0.562 | Steps = 12324\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [00:28<00:41,  1.49s/it][Learner] Episodes = 120 | Gradient Norm = 1.727 | Loss = 0.445 | Steps = 12630\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [00:29<00:36,  1.37s/it][Learner] Episodes = 130 | Gradient Norm = 4.247 | Loss = 0.376 | Steps = 12947\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 131 | Steps = 13051 | Steps Per Second = 410.989\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [00:30<00:38,  1.48s/it][Learner] Episodes = 140 | Gradient Norm = 2.699 | Loss = 0.331 | Steps = 13772\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [00:32<00:34,  1.39s/it][Learner] Episodes = 150 | Gradient Norm = 3.264 | Loss = 0.397 | Steps = 14197\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [00:33<00:30,  1.26s/it][Learner] Episodes = 160 | Gradient Norm = 4.264 | Loss = 0.389 | Steps = 14462\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [00:34<00:28,  1.25s/it][Learner] Episodes = 170 | Gradient Norm = 3.949 | Loss = 0.301 | Steps = 14858\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [00:35<00:27,  1.23s/it][Learner] Episodes = 180 | Gradient Norm = 2.364 | Loss = 0.241 | Steps = 15228\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [00:36<00:23,  1.10s/it][Learner] Episodes = 190 | Gradient Norm = 3.327 | Loss = 0.291 | Steps = 15480\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [00:37<00:20,  1.03s/it][Learner] Episodes = 200 | Gradient Norm = 2.088 | Loss = 0.172 | Steps = 15731\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 21/40 [00:37<00:18,  1.02it/s][Learner] Episodes = 210 | Gradient Norm = 1.920 | Loss = 0.157 | Steps = 15954\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [00:39<00:19,  1.09s/it][Learner] Episodes = 220 | Gradient Norm = 2.236 | Loss = 0.265 | Steps = 16251\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 221 | Steps = 16322 | Steps Per Second = 399.450\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [00:40<00:18,  1.07s/it][Learner] Episodes = 230 | Gradient Norm = 2.232 | Loss = 0.175 | Steps = 16528\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [00:41<00:15,  1.04it/s][Learner] Episodes = 240 | Gradient Norm = 2.066 | Loss = 0.146 | Steps = 16745\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [00:42<00:14,  1.03it/s][Learner] Episodes = 250 | Gradient Norm = 2.509 | Loss = 0.144 | Steps = 16912\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [00:43<00:13,  1.01it/s][Learner] Episodes = 260 | Gradient Norm = 1.421 | Loss = 0.120 | Steps = 17099\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [00:44<00:12,  1.03it/s][Learner] Episodes = 270 | Gradient Norm = 1.571 | Loss = 0.105 | Steps = 17269\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [00:45<00:11,  1.02it/s][Learner] Episodes = 280 | Gradient Norm = 1.668 | Loss = 0.124 | Steps = 17432\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [00:46<00:10,  1.02it/s][Learner] Episodes = 290 | Gradient Norm = 1.042 | Loss = 0.085 | Steps = 17589\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [00:47<00:09,  1.02it/s][Learner] Episodes = 300 | Gradient Norm = 1.428 | Loss = 0.087 | Steps = 17759\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [00:47<00:08,  1.03it/s][Learner] Episodes = 310 | Gradient Norm = 4.123 | Loss = 0.109 | Steps = 17918\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [00:49<00:07,  1.00it/s][Learner] Episodes = 320 | Gradient Norm = 1.061 | Loss = 0.051 | Steps = 18108\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 324 | Steps = 18155 | Steps Per Second = 546.530\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [00:49<00:06,  1.03it/s][Learner] Episodes = 330 | Gradient Norm = 1.516 | Loss = 0.086 | Steps = 18272\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [00:50<00:05,  1.05it/s][Learner] Episodes = 340 | Gradient Norm = 3.190 | Loss = 0.121 | Steps = 18419\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 35/40 [00:51<00:04,  1.04it/s][Learner] Episodes = 350 | Gradient Norm = 1.278 | Loss = 0.045 | Steps = 18565\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [00:52<00:03,  1.02it/s][Learner] Episodes = 360 | Gradient Norm = 1.278 | Loss = 0.043 | Steps = 18731\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [00:54<00:01,  1.04it/s][Learner] Episodes = 380 | Gradient Norm = 1.290 | Loss = 0.065 | Steps = 18927\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [00:55<00:00,  1.02it/s][Learner] Episodes = 390 | Gradient Norm = 1.618 | Loss = 0.045 | Steps = 19083\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:56<00:00,  1.42s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/11e878de-f1da-11ea-9ee7-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:50:11.140265 140374620792704 builder_impl.py:775] Assets written to: /root/acme/11e878de-f1da-11ea-9ee7-0242ac1c0002/snapshots/network/assets\n",
            "I0908 13:50:11.146998 140374620792704 savers.py:156] Saving checkpoint: /root/acme/11e878de-f1da-11ea-9ee7-0242ac1c0002/checkpoints/bc_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/11e878de-f1da-11ea-9ee7-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1650\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 399\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 19234\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599573010.9606102\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 61.23533892631531\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 11\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.9801999926567078\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 523.3008642787469\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/11e878de-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group bc-eps0-ng-Empty-Ran...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599572949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K13mCXqCa1RB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b42e33c3-638a-4429-808e-1e09e257ef7a"
      },
      "source": [
        "for i in range(3):\n",
        "  !python run_offline_crr.py --dataset_dir=$dataset_dir \\\n",
        "                            --environment_name=$environment_name \\\n",
        "                            --epochs=40 \\\n",
        "                            --cql_alpha=0.01 \\\n",
        "                            --policy_improvement_mode='exp' \\\n",
        "                            --logs_tag='crrql-0.01-exp-eps0-Empty-Random-6x6-1step' \\\n",
        "                            --max_eval_episode_len=500 \\\n",
        "                            --n_step_returns=1 \\\n",
        "                            --learning_rate=1e-4 \\\n",
        "                            --wandb_id=''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.7 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_215301-1599601981\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599601981\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599601981\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "_____Evaluating counts for all state action pairs_____ \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [04:04<00:00,  4.09it/s]\n",
            "I0908 21:57:09.717218 140561652021120 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]I0908 21:57:11.018711 140561652021120 savers.py:156] Saving checkpoint: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/checkpoints/crr_learner\n",
            "INFO:tensorflow:Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 21:57:11.334050 140561652021120 builder_impl.py:775] Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 21:57:11.438744 140561652021120 builder_impl.py:775] Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/critic/assets\n",
            "[Learner] Advantage = 0.005 | Critic Loss = 0.003 | Learner Steps = 65 | Policy Loss = 1.123 | Push Down = 1.105 | Push Up = 1.060 | Q Average = 1.060 | Q Variance = 0.002 | Walltime = 9.335\n",
            "[Evalloop] Episode Length = 107 | Episode Return = 0.807 | Episodes = 1 | Learner Steps = 100 | Steps = 107 | Steps Per Second = 383.763 | Walltime = 14.024\n",
            "  2%|‚ñà                                           | 1/40 [00:16<10:49, 16.65s/it][Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 10 | Learner Steps = 121 | Policy Loss = 1.115 | Push Down = 1.054 | Push Up = 1.020 | Q Average = 1.020 | Q Variance = 0.001 | Steps = 698 | Walltime = 19.356\n",
            "[Learner] Advantage = -0.004 | Critic Loss = 0.001 | Episodes = 10 | Learner Steps = 198 | Policy Loss = 1.109 | Push Down = 1.043 | Push Up = 1.018 | Q Average = 1.018 | Q Variance = 0.001 | Steps = 698 | Walltime = 29.413\n",
            "[Evalloop] Episode Length = 97 | Episode Return = 0.825 | Episodes = 11 | Learner Steps = 200 | Steps = 795 | Steps Per Second = 782.739 | Walltime = 29.660\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:32<10:24, 16.44s/it][Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 20 | Learner Steps = 254 | Policy Loss = 1.101 | Push Down = 1.018 | Push Up = 1.000 | Q Average = 1.000 | Q Variance = 0.000 | Steps = 1881 | Walltime = 39.538\n",
            "[Evalloop] Episode Length = 182 | Episode Return = 0.672 | Episodes = 21 | Learner Steps = 300 | Steps = 2063 | Steps Per Second = 812.777 | Walltime = 45.582\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:48<09:59, 16.21s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 30 | Learner Steps = 309 | Policy Loss = 1.098 | Push Down = 0.958 | Push Up = 0.941 | Q Average = 0.941 | Q Variance = 0.000 | Steps = 2958 | Walltime = 49.577\n",
            "[Learner] Advantage = -0.003 | Critic Loss = 0.000 | Episodes = 30 | Learner Steps = 386 | Policy Loss = 1.100 | Push Down = 0.982 | Push Up = 0.965 | Q Average = 0.965 | Q Variance = 0.000 | Steps = 2958 | Walltime = 59.611\n",
            "[Evalloop] Episode Length = 20 | Episode Return = 0.964 | Episodes = 31 | Learner Steps = 400 | Steps = 2978 | Steps Per Second = 735.998 | Walltime = 61.387\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [01:04<09:38, 16.07s/it][Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 40 | Learner Steps = 444 | Policy Loss = 1.075 | Push Down = 0.961 | Push Up = 0.948 | Q Average = 0.948 | Q Variance = 0.000 | Steps = 3786 | Walltime = 69.618\n",
            "[Evalloop] Episode Length = 304 | Episode Return = 0.453 | Episodes = 41 | Learner Steps = 500 | Steps = 4090 | Steps Per Second = 819.788 | Walltime = 77.020\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [01:19<09:19, 15.98s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 50 | Learner Steps = 501 | Policy Loss = 1.110 | Push Down = 0.959 | Push Up = 0.945 | Q Average = 0.945 | Q Variance = 0.000 | Steps = 4840 | Walltime = 79.916\n",
            "[Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 50 | Learner Steps = 577 | Policy Loss = 1.081 | Push Down = 0.950 | Push Up = 0.937 | Q Average = 0.937 | Q Variance = 0.000 | Steps = 4840 | Walltime = 89.948\n",
            "[Evalloop] Episode Length = 31 | Episode Return = 0.944 | Episodes = 51 | Learner Steps = 600 | Steps = 4871 | Steps Per Second = 756.478 | Walltime = 92.957\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [01:36<09:08, 16.13s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 60 | Learner Steps = 629 | Policy Loss = 1.090 | Push Down = 0.914 | Push Up = 0.902 | Q Average = 0.901 | Q Variance = 0.000 | Steps = 6141 | Walltime = 100.034\n",
            "[Evalloop] Episode Length = 16 | Episode Return = 0.971 | Episodes = 61 | Learner Steps = 700 | Steps = 6157 | Steps Per Second = 763.859 | Walltime = 109.405\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [01:51<08:47, 15.98s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 70 | Learner Steps = 701 | Policy Loss = 1.108 | Push Down = 0.927 | Push Up = 0.913 | Q Average = 0.913 | Q Variance = 0.000 | Steps = 6954 | Walltime = 112.007\n",
            "[Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 70 | Learner Steps = 779 | Policy Loss = 1.106 | Push Down = 0.902 | Push Up = 0.889 | Q Average = 0.889 | Q Variance = 0.000 | Steps = 6954 | Walltime = 122.073\n",
            "[Evalloop] Episode Length = 119 | Episode Return = 0.786 | Episodes = 71 | Learner Steps = 800 | Steps = 7073 | Steps Per Second = 782.331 | Walltime = 124.807\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [02:08<08:34, 16.07s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 80 | Learner Steps = 830 | Policy Loss = 1.089 | Push Down = 0.887 | Push Up = 0.873 | Q Average = 0.873 | Q Variance = 0.000 | Steps = 8515 | Walltime = 132.164\n",
            "[Evalloop] Episode Length = 88 | Episode Return = 0.842 | Episodes = 81 | Learner Steps = 900 | Steps = 8603 | Steps Per Second = 751.816 | Walltime = 141.365\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [02:24<08:16, 16.01s/it][Learner] Advantage = -0.003 | Critic Loss = 0.001 | Episodes = 90 | Learner Steps = 901 | Policy Loss = 1.140 | Push Down = 0.903 | Push Up = 0.888 | Q Average = 0.888 | Q Variance = 0.000 | Steps = 9275 | Walltime = 144.173\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 90 | Learner Steps = 979 | Policy Loss = 1.082 | Push Down = 0.895 | Push Up = 0.881 | Q Average = 0.881 | Q Variance = 0.000 | Steps = 9275 | Walltime = 154.186\n",
            "[Evalloop] Episode Length = 43 | Episode Return = 0.923 | Episodes = 91 | Learner Steps = 1000 | Steps = 9318 | Steps Per Second = 797.795 | Walltime = 157.043\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [02:38<07:49, 15.66s/it][Learner] Advantage = -0.000 | Critic Loss = 0.000 | Episodes = 100 | Learner Steps = 1042 | Policy Loss = 1.087 | Push Down = 0.868 | Push Up = 0.856 | Q Average = 0.856 | Q Variance = 0.000 | Steps = 9703 | Walltime = 164.282\n",
            "[Evalloop] Episode Length = 38 | Episode Return = 0.932 | Episodes = 101 | Learner Steps = 1100 | Steps = 9741 | Steps Per Second = 602.917 | Walltime = 172.078\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [02:54<07:36, 15.75s/it][Learner] Advantage = 0.003 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1101 | Policy Loss = 1.071 | Push Down = 0.873 | Push Up = 0.859 | Q Average = 0.859 | Q Variance = 0.000 | Steps = 10599 | Walltime = 175.011\n",
            "[Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1172 | Policy Loss = 1.108 | Push Down = 0.859 | Push Up = 0.845 | Q Average = 0.845 | Q Variance = 0.000 | Steps = 10599 | Walltime = 185.043\n",
            "[Evalloop] Episode Length = 44 | Episode Return = 0.921 | Episodes = 111 | Learner Steps = 1200 | Steps = 10643 | Steps Per Second = 694.319 | Walltime = 188.742\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [03:11<07:30, 16.08s/it][Learner] Advantage = -0.001 | Critic Loss = 0.001 | Episodes = 120 | Learner Steps = 1226 | Policy Loss = 1.072 | Push Down = 0.843 | Push Up = 0.827 | Q Average = 0.827 | Q Variance = 0.000 | Steps = 11533 | Walltime = 195.103\n",
            "[Evalloop] Episode Length = 44 | Episode Return = 0.921 | Episodes = 121 | Learner Steps = 1300 | Steps = 11577 | Steps Per Second = 766.560 | Walltime = 204.987\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [03:27<07:11, 15.98s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 130 | Learner Steps = 1301 | Policy Loss = 1.078 | Push Down = 0.856 | Push Up = 0.841 | Q Average = 0.841 | Q Variance = 0.000 | Steps = 12391 | Walltime = 207.573\n",
            "[Learner] Advantage = 0.004 | Critic Loss = 0.000 | Episodes = 130 | Learner Steps = 1377 | Policy Loss = 1.071 | Push Down = 0.852 | Push Up = 0.836 | Q Average = 0.836 | Q Variance = 0.000 | Steps = 12391 | Walltime = 217.663\n",
            "[Evalloop] Episode Length = 80 | Episode Return = 0.856 | Episodes = 131 | Learner Steps = 1400 | Steps = 12471 | Steps Per Second = 751.637 | Walltime = 220.712\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [03:42<06:51, 15.82s/it][Learner] Advantage = -0.000 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1436 | Policy Loss = 1.110 | Push Down = 0.840 | Push Up = 0.825 | Q Average = 0.825 | Q Variance = 0.000 | Steps = 13075 | Walltime = 227.758\n",
            "[Evalloop] Episode Length = 59 | Episode Return = 0.894 | Episodes = 141 | Learner Steps = 1500 | Steps = 13134 | Steps Per Second = 710.189 | Walltime = 236.233\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [03:58<06:36, 15.85s/it][Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 150 | Learner Steps = 1501 | Policy Loss = 1.079 | Push Down = 0.823 | Push Up = 0.805 | Q Average = 0.805 | Q Variance = 0.000 | Steps = 14030 | Walltime = 238.951\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.004 | Episodes = 150 | Learner Steps = 1575 | Policy Loss = 1.073 | Push Down = 0.823 | Push Up = 0.805 | Q Average = 0.805 | Q Variance = 0.000 | Steps = 14030 | Walltime = 249.067\n",
            "[Evalloop] Episode Length = 242 | Episode Return = 0.564 | Episodes = 151 | Learner Steps = 1600 | Steps = 14272 | Steps Per Second = 738.513 | Walltime = 252.573\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [04:15<06:24, 16.01s/it][Learner] Advantage = -0.000 | Critic Loss = 0.000 | Episodes = 160 | Learner Steps = 1629 | Policy Loss = 1.107 | Push Down = 0.777 | Push Up = 0.763 | Q Average = 0.763 | Q Variance = 0.000 | Steps = 14947 | Walltime = 259.198\n",
            "[Evalloop] Episode Length = 77 | Episode Return = 0.861 | Episodes = 161 | Learner Steps = 1700 | Steps = 15024 | Steps Per Second = 703.339 | Walltime = 268.986\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [04:32<06:14, 16.30s/it][Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 170 | Learner Steps = 1701 | Policy Loss = 1.082 | Push Down = 0.793 | Push Up = 0.777 | Q Average = 0.777 | Q Variance = 0.000 | Steps = 15826 | Walltime = 272.307\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 170 | Learner Steps = 1777 | Policy Loss = 1.102 | Push Down = 0.790 | Push Up = 0.772 | Q Average = 0.772 | Q Variance = 0.000 | Steps = 15826 | Walltime = 282.388\n",
            "[Evalloop] Episode Length = 63 | Episode Return = 0.887 | Episodes = 171 | Learner Steps = 1800 | Steps = 15889 | Steps Per Second = 784.545 | Walltime = 285.390\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [04:48<05:56, 16.20s/it][Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 180 | Learner Steps = 1832 | Policy Loss = 1.106 | Push Down = 0.780 | Push Up = 0.762 | Q Average = 0.762 | Q Variance = 0.000 | Steps = 16906 | Walltime = 292.442\n",
            "[Evalloop] Episode Length = 58 | Episode Return = 0.896 | Episodes = 181 | Learner Steps = 1900 | Steps = 16964 | Steps Per Second = 742.665 | Walltime = 301.624\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [05:04<05:38, 16.10s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 190 | Learner Steps = 1901 | Policy Loss = 1.065 | Push Down = 0.780 | Push Up = 0.763 | Q Average = 0.763 | Q Variance = 0.000 | Steps = 17653 | Walltime = 304.145\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 190 | Learner Steps = 1977 | Policy Loss = 1.077 | Push Down = 0.765 | Push Up = 0.747 | Q Average = 0.747 | Q Variance = 0.000 | Steps = 17653 | Walltime = 314.154\n",
            "[Evalloop] Episode Length = 7 | Episode Return = 0.987 | Episodes = 191 | Learner Steps = 2000 | Steps = 17660 | Steps Per Second = 643.623 | Walltime = 317.120\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [05:20<05:21, 16.09s/it][Learner] Advantage = 0.006 | Critic Loss = 0.001 | Episodes = 200 | Learner Steps = 2031 | Policy Loss = 1.080 | Push Down = 0.757 | Push Up = 0.735 | Q Average = 0.735 | Q Variance = 0.000 | Steps = 18861 | Walltime = 324.240\n",
            "[Evalloop] Episode Length = 124 | Episode Return = 0.777 | Episodes = 201 | Learner Steps = 2100 | Steps = 18985 | Steps Per Second = 685.022 | Walltime = 333.629\n",
            "/content/visualization.py:111: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(17, 12))\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 21/40 [05:35<05:03, 15.97s/it][Learner] Advantage = -0.001 | Critic Loss = 0.001 | Episodes = 210 | Learner Steps = 2101 | Policy Loss = 1.087 | Push Down = 0.750 | Push Up = 0.731 | Q Average = 0.731 | Q Variance = 0.000 | Steps = 19337 | Walltime = 335.894\n",
            "[Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 210 | Learner Steps = 2175 | Policy Loss = 1.100 | Push Down = 0.748 | Push Up = 0.727 | Q Average = 0.727 | Q Variance = 0.000 | Steps = 19337 | Walltime = 345.973\n",
            "[Evalloop] Episode Length = 27 | Episode Return = 0.951 | Episodes = 211 | Learner Steps = 2200 | Steps = 19364 | Steps Per Second = 753.984 | Walltime = 349.196\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [05:52<04:50, 16.12s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 220 | Learner Steps = 2229 | Policy Loss = 1.077 | Push Down = 0.763 | Push Up = 0.735 | Q Average = 0.735 | Q Variance = 0.001 | Steps = 20039 | Walltime = 356.102\n",
            "[Evalloop] Episode Length = 81 | Episode Return = 0.854 | Episodes = 221 | Learner Steps = 2300 | Steps = 20120 | Steps Per Second = 719.842 | Walltime = 365.651\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [06:08<04:33, 16.11s/it][Learner] Advantage = 0.000 | Critic Loss = 0.001 | Episodes = 230 | Learner Steps = 2301 | Policy Loss = 1.088 | Push Down = 0.725 | Push Up = 0.708 | Q Average = 0.708 | Q Variance = 0.000 | Steps = 21013 | Walltime = 368.466\n",
            "[Learner] Advantage = 0.008 | Critic Loss = 0.001 | Episodes = 230 | Learner Steps = 2377 | Policy Loss = 1.097 | Push Down = 0.742 | Push Up = 0.720 | Q Average = 0.720 | Q Variance = 0.000 | Steps = 21013 | Walltime = 378.580\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 231 | Learner Steps = 2400 | Steps = 21017 | Steps Per Second = 550.524 | Walltime = 381.673\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [06:23<04:15, 15.96s/it][Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 240 | Learner Steps = 2433 | Policy Loss = 1.093 | Push Down = 0.746 | Push Up = 0.719 | Q Average = 0.719 | Q Variance = 0.001 | Steps = 21678 | Walltime = 388.586\n",
            "[Evalloop] Episode Length = 13 | Episode Return = 0.977 | Episodes = 241 | Learner Steps = 2500 | Steps = 21691 | Steps Per Second = 621.541 | Walltime = 397.512\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [06:39<03:58, 15.91s/it][Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 250 | Learner Steps = 2501 | Policy Loss = 1.093 | Push Down = 0.732 | Push Up = 0.711 | Q Average = 0.711 | Q Variance = 0.000 | Steps = 22364 | Walltime = 399.865\n",
            "[Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 250 | Learner Steps = 2577 | Policy Loss = 1.087 | Push Down = 0.743 | Push Up = 0.716 | Q Average = 0.716 | Q Variance = 0.001 | Steps = 22364 | Walltime = 409.998\n",
            "[Evalloop] Episode Length = 6 | Episode Return = 0.989 | Episodes = 251 | Learner Steps = 2600 | Steps = 22370 | Steps Per Second = 617.460 | Walltime = 413.155\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [06:55<03:42, 15.86s/it][Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 260 | Learner Steps = 2634 | Policy Loss = 1.107 | Push Down = 0.730 | Push Up = 0.709 | Q Average = 0.709 | Q Variance = 0.000 | Steps = 23083 | Walltime = 420.059\n",
            "[Evalloop] Episode Length = 10 | Episode Return = 0.982 | Episodes = 261 | Learner Steps = 2700 | Steps = 23093 | Steps Per Second = 686.769 | Walltime = 428.844\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [07:11<03:25, 15.82s/it][Learner] Advantage = 0.006 | Critic Loss = 0.004 | Episodes = 270 | Learner Steps = 2701 | Policy Loss = 1.067 | Push Down = 0.720 | Push Up = 0.695 | Q Average = 0.695 | Q Variance = 0.001 | Steps = 23815 | Walltime = 431.339\n",
            "[Learner] Advantage = -0.004 | Critic Loss = 0.001 | Episodes = 270 | Learner Steps = 2775 | Policy Loss = 1.063 | Push Down = 0.700 | Push Up = 0.676 | Q Average = 0.676 | Q Variance = 0.001 | Steps = 23815 | Walltime = 441.383\n",
            "[Evalloop] Episode Length = 110 | Episode Return = 0.802 | Episodes = 271 | Learner Steps = 2800 | Steps = 23925 | Steps Per Second = 730.102 | Walltime = 444.787\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [07:27<03:10, 15.85s/it][Learner] Advantage = 0.005 | Critic Loss = 0.001 | Episodes = 280 | Learner Steps = 2833 | Policy Loss = 1.094 | Push Down = 0.701 | Push Up = 0.679 | Q Average = 0.678 | Q Variance = 0.000 | Steps = 24544 | Walltime = 451.519\n",
            "[Evalloop] Episode Length = 18 | Episode Return = 0.968 | Episodes = 281 | Learner Steps = 2900 | Steps = 24562 | Steps Per Second = 732.338 | Walltime = 460.678\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [07:43<02:56, 16.07s/it][Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 290 | Learner Steps = 2901 | Policy Loss = 1.084 | Push Down = 0.709 | Push Up = 0.686 | Q Average = 0.686 | Q Variance = 0.000 | Steps = 25079 | Walltime = 463.832\n",
            "[Learner] Advantage = -0.003 | Critic Loss = 0.001 | Episodes = 290 | Learner Steps = 2977 | Policy Loss = 1.114 | Push Down = 0.687 | Push Up = 0.665 | Q Average = 0.665 | Q Variance = 0.000 | Steps = 25079 | Walltime = 473.923\n",
            "[Evalloop] Episode Length = 43 | Episode Return = 0.923 | Episodes = 291 | Learner Steps = 3000 | Steps = 25122 | Steps Per Second = 773.761 | Walltime = 477.001\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [07:59<02:38, 15.90s/it][Learner] Advantage = 0.005 | Critic Loss = 0.001 | Episodes = 300 | Learner Steps = 3035 | Policy Loss = 1.038 | Push Down = 0.704 | Push Up = 0.673 | Q Average = 0.673 | Q Variance = 0.001 | Steps = 25746 | Walltime = 484.033\n",
            "[Evalloop] Episode Length = 64 | Episode Return = 0.885 | Episodes = 301 | Learner Steps = 3100 | Steps = 25810 | Steps Per Second = 715.874 | Walltime = 493.416\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [08:15<02:24, 16.02s/it][Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 310 | Learner Steps = 3101 | Policy Loss = 1.068 | Push Down = 0.693 | Push Up = 0.670 | Q Average = 0.671 | Q Variance = 0.000 | Steps = 26290 | Walltime = 495.631\n",
            "[Learner] Advantage = 0.005 | Critic Loss = 0.001 | Episodes = 310 | Learner Steps = 3175 | Policy Loss = 1.062 | Push Down = 0.677 | Push Up = 0.649 | Q Average = 0.650 | Q Variance = 0.001 | Steps = 26290 | Walltime = 505.723\n",
            "[Evalloop] Episode Length = 50 | Episode Return = 0.910 | Episodes = 311 | Learner Steps = 3200 | Steps = 26340 | Steps Per Second = 765.216 | Walltime = 509.191\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [08:31<02:07, 15.94s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 320 | Learner Steps = 3234 | Policy Loss = 1.107 | Push Down = 0.682 | Push Up = 0.653 | Q Average = 0.653 | Q Variance = 0.001 | Steps = 26794 | Walltime = 515.768\n",
            "[Evalloop] Episode Length = 61 | Episode Return = 0.890 | Episodes = 321 | Learner Steps = 3300 | Steps = 26855 | Steps Per Second = 685.794 | Walltime = 524.653\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [08:46<01:50, 15.80s/it][Learner] Advantage = -0.001 | Critic Loss = 0.005 | Episodes = 330 | Learner Steps = 3301 | Policy Loss = 1.071 | Push Down = 0.705 | Push Up = 0.675 | Q Average = 0.675 | Q Variance = 0.001 | Steps = 27305 | Walltime = 526.870\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 330 | Learner Steps = 3375 | Policy Loss = 1.055 | Push Down = 0.682 | Push Up = 0.650 | Q Average = 0.650 | Q Variance = 0.001 | Steps = 27305 | Walltime = 536.884\n",
            "[Evalloop] Episode Length = 3 | Episode Return = 0.995 | Episodes = 331 | Learner Steps = 3400 | Steps = 27308 | Steps Per Second = 588.619 | Walltime = 540.221\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [09:02<01:34, 15.78s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 340 | Learner Steps = 3433 | Policy Loss = 1.079 | Push Down = 0.646 | Push Up = 0.627 | Q Average = 0.627 | Q Variance = 0.000 | Steps = 27957 | Walltime = 547.009\n",
            "[Evalloop] Episode Length = 31 | Episode Return = 0.944 | Episodes = 341 | Learner Steps = 3500 | Steps = 27988 | Steps Per Second = 663.507 | Walltime = 556.336\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 35/40 [09:18<01:19, 15.83s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 350 | Learner Steps = 3501 | Policy Loss = 1.073 | Push Down = 0.669 | Push Up = 0.642 | Q Average = 0.642 | Q Variance = 0.001 | Steps = 28492 | Walltime = 558.538\n",
            "[Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 350 | Learner Steps = 3576 | Policy Loss = 1.074 | Push Down = 0.682 | Push Up = 0.646 | Q Average = 0.646 | Q Variance = 0.001 | Steps = 28492 | Walltime = 568.620\n",
            "[Evalloop] Episode Length = 73 | Episode Return = 0.869 | Episodes = 351 | Learner Steps = 3600 | Steps = 28565 | Steps Per Second = 715.842 | Walltime = 571.774\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [09:33<01:02, 15.73s/it][Learner] Advantage = 0.000 | Critic Loss = 0.001 | Episodes = 360 | Learner Steps = 3635 | Policy Loss = 1.100 | Push Down = 0.663 | Push Up = 0.633 | Q Average = 0.633 | Q Variance = 0.001 | Steps = 29016 | Walltime = 578.632\n",
            "[Evalloop] Episode Length = 146 | Episode Return = 0.737 | Episodes = 361 | Learner Steps = 3700 | Steps = 29162 | Steps Per Second = 750.049 | Walltime = 587.404\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/40 [09:51<00:48, 16.19s/it][Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 370 | Learner Steps = 3701 | Policy Loss = 1.081 | Push Down = 0.637 | Push Up = 0.612 | Q Average = 0.612 | Q Variance = 0.001 | Steps = 29925 | Walltime = 591.303\n",
            "I0908 22:07:11.327207 140561652021120 savers.py:156] Saving checkpoint: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/checkpoints/crr_learner\n",
            "INFO:tensorflow:Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 22:07:11.622766 140561652021120 builder_impl.py:775] Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:07:11.700087 140561652021120 builder_impl.py:775] Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/critic/assets\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 370 | Learner Steps = 3773 | Policy Loss = 1.080 | Push Down = 0.657 | Push Up = 0.628 | Q Average = 0.628 | Q Variance = 0.001 | Steps = 29925 | Walltime = 601.377\n",
            "[Evalloop] Episode Length = 437 | Episode Return = 0.213 | Episodes = 371 | Learner Steps = 3800 | Steps = 30362 | Steps Per Second = 757.817 | Walltime = 605.167\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [10:07<00:32, 16.22s/it][Learner] Advantage = -0.001 | Critic Loss = 0.001 | Episodes = 380 | Learner Steps = 3830 | Policy Loss = 1.113 | Push Down = 0.664 | Push Up = 0.635 | Q Average = 0.635 | Q Variance = 0.001 | Steps = 30645 | Walltime = 611.427\n",
            "[Evalloop] Episode Length = 16 | Episode Return = 0.971 | Episodes = 381 | Learner Steps = 3900 | Steps = 30661 | Steps Per Second = 710.478 | Walltime = 620.911\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [10:23<00:16, 16.06s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 390 | Learner Steps = 3901 | Policy Loss = 1.085 | Push Down = 0.689 | Push Up = 0.659 | Q Average = 0.659 | Q Variance = 0.001 | Steps = 31331 | Walltime = 623.282\n",
            "[Learner] Advantage = -0.001 | Critic Loss = 0.001 | Episodes = 390 | Learner Steps = 3975 | Policy Loss = 1.071 | Push Down = 0.672 | Push Up = 0.640 | Q Average = 0.640 | Q Variance = 0.001 | Steps = 31331 | Walltime = 633.307\n",
            "[Evalloop] Episode Length = 117 | Episode Return = 0.789 | Episodes = 391 | Learner Steps = 4000 | Steps = 31448 | Steps Per Second = 757.050 | Walltime = 636.687\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [10:38<00:00, 15.97s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 22:07:49.344307 140561652021120 builder_impl.py:775] Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:07:49.408271 140561652021120 builder_impl.py:775] Assets written to: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:07:49.412178 140561652021120 savers.py:156] Saving checkpoint: /root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002/checkpoints/crr_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/a87beac2-f21d-11ea-9fac-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3441\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/walltime 636.687185049057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 890.816344499588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/policy_loss 1.0859320163726807\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          Learner/q_variance 0.0012334255734458566\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 4439\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Learner/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Learner/push_up 0.6408601999282837\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599602868.5832658\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/critic_loss 0.0008850443991832435\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/push_down 0.6786969900131226\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/q_average 0.6410745978355408\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/advantage -0.000372148584574461\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/walltime 636.687185049057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.9909999966621399\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 716.53409867432\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 31872\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      EvalLoop/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch_counter 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/episodes 390\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Learner/steps 31331\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/a87beac2-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group crrql-0.01-exp-eps0-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 40 media file(s), 10 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599601981\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.7 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_220802-1599602882\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599602882\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599602882\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "_____Evaluating counts for all state action pairs_____ \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [04:18<00:00,  3.87it/s]\n",
            "I0908 22:12:24.346268 140521074534272 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]I0908 22:12:25.704770 140521074534272 savers.py:156] Saving checkpoint: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/checkpoints/crr_learner\n",
            "INFO:tensorflow:Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 22:12:26.036912 140521074534272 builder_impl.py:775] Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:12:26.138695 140521074534272 builder_impl.py:775] Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/critic/assets\n",
            "[Learner] Advantage = -0.003 | Critic Loss = 0.003 | Learner Steps = 62 | Policy Loss = 1.099 | Push Down = 1.082 | Push Up = 1.040 | Q Average = 1.040 | Q Variance = 0.002 | Walltime = 9.185\n",
            "[Evalloop] Episode Length = 107 | Episode Return = 0.807 | Episodes = 1 | Learner Steps = 100 | Steps = 107 | Steps Per Second = 440.389 | Walltime = 14.339\n",
            "  2%|‚ñà                                           | 1/40 [00:17<11:26, 17.61s/it][Learner] Advantage = 0.009 | Critic Loss = 0.001 | Episodes = 10 | Learner Steps = 112 | Policy Loss = 1.102 | Push Down = 1.048 | Push Up = 1.013 | Q Average = 1.013 | Q Variance = 0.001 | Steps = 1200 | Walltime = 19.231\n",
            "[Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 10 | Learner Steps = 186 | Policy Loss = 1.110 | Push Down = 1.030 | Push Up = 1.004 | Q Average = 1.004 | Q Variance = 0.001 | Steps = 1200 | Walltime = 29.250\n",
            "[Evalloop] Episode Length = 9 | Episode Return = 0.984 | Episodes = 11 | Learner Steps = 200 | Steps = 1209 | Steps Per Second = 653.624 | Walltime = 31.155\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:33<10:53, 17.20s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 20 | Learner Steps = 241 | Policy Loss = 1.100 | Push Down = 1.017 | Push Up = 0.997 | Q Average = 0.996 | Q Variance = 0.000 | Steps = 2026 | Walltime = 39.351\n",
            "[Evalloop] Episode Length = 49 | Episode Return = 0.912 | Episodes = 21 | Learner Steps = 300 | Steps = 2075 | Steps Per Second = 768.033 | Walltime = 47.369\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:49<10:20, 16.76s/it][Learner] Advantage = -0.002 | Critic Loss = 0.000 | Episodes = 30 | Learner Steps = 301 | Policy Loss = 1.106 | Push Down = 1.001 | Push Up = 0.982 | Q Average = 0.982 | Q Variance = 0.000 | Steps = 2667 | Walltime = 49.728\n",
            "[Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 30 | Learner Steps = 376 | Policy Loss = 1.080 | Push Down = 0.984 | Push Up = 0.969 | Q Average = 0.969 | Q Variance = 0.000 | Steps = 2667 | Walltime = 59.770\n",
            "[Evalloop] Episode Length = 25 | Episode Return = 0.955 | Episodes = 31 | Learner Steps = 400 | Steps = 2692 | Steps Per Second = 730.491 | Walltime = 63.039\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [01:05<09:59, 16.64s/it][Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 40 | Learner Steps = 428 | Policy Loss = 1.077 | Push Down = 0.964 | Push Up = 0.947 | Q Average = 0.947 | Q Variance = 0.000 | Steps = 3650 | Walltime = 69.771\n",
            "[Evalloop] Episode Length = 119 | Episode Return = 0.786 | Episodes = 41 | Learner Steps = 500 | Steps = 3769 | Steps Per Second = 657.427 | Walltime = 79.451\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [01:22<09:41, 16.61s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 50 | Learner Steps = 501 | Policy Loss = 1.120 | Push Down = 0.956 | Push Up = 0.943 | Q Average = 0.943 | Q Variance = 0.000 | Steps = 4784 | Walltime = 82.612\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.002 | Episodes = 50 | Learner Steps = 575 | Policy Loss = 1.088 | Push Down = 0.937 | Push Up = 0.923 | Q Average = 0.923 | Q Variance = 0.000 | Steps = 4784 | Walltime = 92.698\n",
            "[Evalloop] Episode Length = 31 | Episode Return = 0.944 | Episodes = 51 | Learner Steps = 600 | Steps = 4815 | Steps Per Second = 746.643 | Walltime = 96.048\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [01:38<09:22, 16.53s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 60 | Learner Steps = 629 | Policy Loss = 1.090 | Push Down = 0.917 | Push Up = 0.904 | Q Average = 0.904 | Q Variance = 0.000 | Steps = 5598 | Walltime = 102.762\n",
            "[Evalloop] Episode Length = 76 | Episode Return = 0.863 | Episodes = 61 | Learner Steps = 700 | Steps = 5674 | Steps Per Second = 710.901 | Walltime = 112.381\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [01:55<09:03, 16.46s/it][Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 70 | Learner Steps = 701 | Policy Loss = 1.079 | Push Down = 0.921 | Push Up = 0.908 | Q Average = 0.908 | Q Variance = 0.000 | Steps = 6637 | Walltime = 115.281\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 70 | Learner Steps = 775 | Policy Loss = 1.103 | Push Down = 0.902 | Push Up = 0.891 | Q Average = 0.891 | Q Variance = 0.000 | Steps = 6637 | Walltime = 125.364\n",
            "[Evalloop] Episode Length = 52 | Episode Return = 0.906 | Episodes = 71 | Learner Steps = 800 | Steps = 6689 | Steps Per Second = 709.696 | Walltime = 128.734\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [02:10<08:40, 16.27s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 80 | Learner Steps = 833 | Policy Loss = 1.086 | Push Down = 0.898 | Push Up = 0.883 | Q Average = 0.883 | Q Variance = 0.000 | Steps = 7285 | Walltime = 135.393\n",
            "[Evalloop] Episode Length = 48 | Episode Return = 0.914 | Episodes = 81 | Learner Steps = 900 | Steps = 7333 | Steps Per Second = 672.465 | Walltime = 144.498\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [02:27<08:22, 16.21s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 90 | Learner Steps = 901 | Policy Loss = 1.079 | Push Down = 0.894 | Push Up = 0.881 | Q Average = 0.881 | Q Variance = 0.000 | Steps = 7813 | Walltime = 147.169\n",
            "[Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 90 | Learner Steps = 975 | Policy Loss = 1.081 | Push Down = 0.877 | Push Up = 0.864 | Q Average = 0.864 | Q Variance = 0.000 | Steps = 7813 | Walltime = 157.244\n",
            "[Evalloop] Episode Length = 40 | Episode Return = 0.928 | Episodes = 91 | Learner Steps = 1000 | Steps = 7853 | Steps Per Second = 690.347 | Walltime = 160.719\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [02:43<08:05, 16.19s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 100 | Learner Steps = 1031 | Policy Loss = 1.072 | Push Down = 0.855 | Push Up = 0.842 | Q Average = 0.842 | Q Variance = 0.000 | Steps = 8636 | Walltime = 167.353\n",
            "[Evalloop] Episode Length = 54 | Episode Return = 0.903 | Episodes = 101 | Learner Steps = 1100 | Steps = 8690 | Steps Per Second = 769.095 | Walltime = 176.887\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [03:00<07:55, 16.38s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1101 | Policy Loss = 1.081 | Push Down = 0.856 | Push Up = 0.842 | Q Average = 0.842 | Q Variance = 0.000 | Steps = 9943 | Walltime = 180.128\n",
            "[Learner] Advantage = -0.000 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1175 | Policy Loss = 1.073 | Push Down = 0.847 | Push Up = 0.834 | Q Average = 0.834 | Q Variance = 0.000 | Steps = 9943 | Walltime = 190.159\n",
            "[Evalloop] Episode Length = 12 | Episode Return = 0.978 | Episodes = 111 | Learner Steps = 1200 | Steps = 9955 | Steps Per Second = 623.920 | Walltime = 193.707\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [03:17<07:44, 16.60s/it][Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 120 | Learner Steps = 1222 | Policy Loss = 1.095 | Push Down = 0.867 | Push Up = 0.843 | Q Average = 0.843 | Q Variance = 0.000 | Steps = 11187 | Walltime = 200.233\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.000 | Episodes = 120 | Learner Steps = 1297 | Policy Loss = 1.086 | Push Down = 0.843 | Push Up = 0.828 | Q Average = 0.828 | Q Variance = 0.000 | Steps = 11187 | Walltime = 210.249\n",
            "[Evalloop] Episode Length = 92 | Episode Return = 0.834 | Episodes = 121 | Learner Steps = 1300 | Steps = 11279 | Steps Per Second = 762.908 | Walltime = 210.661\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [03:33<07:28, 16.62s/it][Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 130 | Learner Steps = 1350 | Policy Loss = 1.077 | Push Down = 0.828 | Push Up = 0.813 | Q Average = 0.813 | Q Variance = 0.000 | Steps = 12084 | Walltime = 220.344\n",
            "[Evalloop] Episode Length = 360 | Episode Return = 0.352 | Episodes = 131 | Learner Steps = 1400 | Steps = 12444 | Steps Per Second = 730.344 | Walltime = 227.264\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [03:49<07:08, 16.47s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1404 | Policy Loss = 1.098 | Push Down = 0.824 | Push Up = 0.810 | Q Average = 0.810 | Q Variance = 0.000 | Steps = 12995 | Walltime = 230.442\n",
            "[Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1477 | Policy Loss = 1.093 | Push Down = 0.807 | Push Up = 0.792 | Q Average = 0.792 | Q Variance = 0.000 | Steps = 12995 | Walltime = 240.519\n",
            "[Evalloop] Episode Length = 105 | Episode Return = 0.811 | Episodes = 141 | Learner Steps = 1500 | Steps = 13100 | Steps Per Second = 745.147 | Walltime = 243.689\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [04:06<06:49, 16.37s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 150 | Learner Steps = 1533 | Policy Loss = 1.076 | Push Down = 0.825 | Push Up = 0.808 | Q Average = 0.808 | Q Variance = 0.000 | Steps = 13702 | Walltime = 250.606\n",
            "[Evalloop] Episode Length = 45 | Episode Return = 0.919 | Episodes = 151 | Learner Steps = 1600 | Steps = 13747 | Steps Per Second = 720.767 | Walltime = 259.982\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [04:22<06:35, 16.48s/it][Learner] Advantage = 0.003 | Critic Loss = 0.000 | Episodes = 160 | Learner Steps = 1601 | Policy Loss = 1.096 | Push Down = 0.809 | Push Up = 0.794 | Q Average = 0.794 | Q Variance = 0.000 | Steps = 14687 | Walltime = 262.926\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 160 | Learner Steps = 1673 | Policy Loss = 1.065 | Push Down = 0.796 | Push Up = 0.779 | Q Average = 0.779 | Q Variance = 0.000 | Steps = 14687 | Walltime = 272.971\n",
            "[Evalloop] Episode Length = 60 | Episode Return = 0.892 | Episodes = 161 | Learner Steps = 1700 | Steps = 14747 | Steps Per Second = 754.962 | Walltime = 276.797\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [04:39<06:19, 16.51s/it][Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 170 | Learner Steps = 1726 | Policy Loss = 1.063 | Push Down = 0.794 | Push Up = 0.776 | Q Average = 0.776 | Q Variance = 0.000 | Steps = 15084 | Walltime = 283.034\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 170 | Learner Steps = 1799 | Policy Loss = 1.101 | Push Down = 0.793 | Push Up = 0.772 | Q Average = 0.772 | Q Variance = 0.000 | Steps = 15084 | Walltime = 293.140\n",
            "[Evalloop] Episode Length = 41 | Episode Return = 0.926 | Episodes = 171 | Learner Steps = 1800 | Steps = 15125 | Steps Per Second = 655.557 | Walltime = 293.275\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [04:55<06:03, 16.52s/it][Learner] Advantage = -0.000 | Critic Loss = 0.000 | Episodes = 180 | Learner Steps = 1851 | Policy Loss = 1.103 | Push Down = 0.785 | Push Up = 0.766 | Q Average = 0.766 | Q Variance = 0.000 | Steps = 15928 | Walltime = 303.244\n",
            "[Evalloop] Episode Length = 138 | Episode Return = 0.752 | Episodes = 181 | Learner Steps = 1900 | Steps = 16066 | Steps Per Second = 735.552 | Walltime = 310.262\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [05:12<05:49, 16.65s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 190 | Learner Steps = 1903 | Policy Loss = 1.091 | Push Down = 0.755 | Push Up = 0.741 | Q Average = 0.741 | Q Variance = 0.000 | Steps = 16769 | Walltime = 313.307\n",
            "[Learner] Advantage = 0.000 | Critic Loss = 0.001 | Episodes = 190 | Learner Steps = 1975 | Policy Loss = 1.101 | Push Down = 0.778 | Push Up = 0.759 | Q Average = 0.759 | Q Variance = 0.000 | Steps = 16769 | Walltime = 323.388\n",
            "[Evalloop] Episode Length = 18 | Episode Return = 0.968 | Episodes = 191 | Learner Steps = 2000 | Steps = 16787 | Steps Per Second = 712.745 | Walltime = 326.846\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [05:28<05:29, 16.48s/it][Learner] Advantage = -0.004 | Critic Loss = 0.000 | Episodes = 200 | Learner Steps = 2032 | Policy Loss = 1.101 | Push Down = 0.761 | Push Up = 0.740 | Q Average = 0.740 | Q Variance = 0.000 | Steps = 17278 | Walltime = 333.423\n",
            "[Evalloop] Episode Length = 285 | Episode Return = 0.487 | Episodes = 201 | Learner Steps = 2100 | Steps = 17563 | Steps Per Second = 708.841 | Walltime = 343.048\n",
            "/content/visualization.py:111: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(17, 12))\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 21/40 [05:45<05:15, 16.63s/it][Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 210 | Learner Steps = 2101 | Policy Loss = 1.102 | Push Down = 0.759 | Push Up = 0.741 | Q Average = 0.741 | Q Variance = 0.000 | Steps = 18315 | Walltime = 346.055\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.000 | Episodes = 210 | Learner Steps = 2173 | Policy Loss = 1.076 | Push Down = 0.764 | Push Up = 0.740 | Q Average = 0.740 | Q Variance = 0.000 | Steps = 18315 | Walltime = 356.193\n",
            "[Evalloop] Episode Length = 97 | Episode Return = 0.825 | Episodes = 211 | Learner Steps = 2200 | Steps = 18412 | Steps Per Second = 740.721 | Walltime = 360.002\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [06:03<05:04, 16.93s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 220 | Learner Steps = 2219 | Policy Loss = 1.064 | Push Down = 0.737 | Push Up = 0.716 | Q Average = 0.716 | Q Variance = 0.000 | Steps = 19281 | Walltime = 366.290\n",
            "[Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 220 | Learner Steps = 2291 | Policy Loss = 1.074 | Push Down = 0.750 | Push Up = 0.727 | Q Average = 0.727 | Q Variance = 0.000 | Steps = 19281 | Walltime = 376.327\n",
            "[Evalloop] Episode Length = 28 | Episode Return = 0.950 | Episodes = 221 | Learner Steps = 2300 | Steps = 19309 | Steps Per Second = 730.651 | Walltime = 377.600\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [06:20<04:45, 16.80s/it][Learner] Advantage = -0.001 | Critic Loss = 0.001 | Episodes = 230 | Learner Steps = 2345 | Policy Loss = 1.094 | Push Down = 0.751 | Push Up = 0.729 | Q Average = 0.729 | Q Variance = 0.000 | Steps = 20026 | Walltime = 386.417\n",
            "[Evalloop] Episode Length = 2 | Episode Return = 0.996 | Episodes = 231 | Learner Steps = 2400 | Steps = 20028 | Steps Per Second = 473.424 | Walltime = 394.323\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [06:36<04:28, 16.77s/it][Learner] Advantage = -0.000 | Critic Loss = 0.000 | Episodes = 240 | Learner Steps = 2401 | Policy Loss = 1.079 | Push Down = 0.734 | Push Up = 0.712 | Q Average = 0.712 | Q Variance = 0.000 | Steps = 20745 | Walltime = 396.890\n",
            "[Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 240 | Learner Steps = 2473 | Policy Loss = 1.084 | Push Down = 0.735 | Push Up = 0.711 | Q Average = 0.711 | Q Variance = 0.000 | Steps = 20745 | Walltime = 407.028\n",
            "[Evalloop] Episode Length = 161 | Episode Return = 0.710 | Episodes = 241 | Learner Steps = 2500 | Steps = 20906 | Steps Per Second = 696.550 | Walltime = 410.881\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [06:53<04:10, 16.67s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 250 | Learner Steps = 2528 | Policy Loss = 1.083 | Push Down = 0.726 | Push Up = 0.705 | Q Average = 0.705 | Q Variance = 0.000 | Steps = 21392 | Walltime = 417.054\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 250 | Learner Steps = 2599 | Policy Loss = 1.094 | Push Down = 0.714 | Push Up = 0.695 | Q Average = 0.695 | Q Variance = 0.000 | Steps = 21392 | Walltime = 427.185\n",
            "[Evalloop] Episode Length = 48 | Episode Return = 0.914 | Episodes = 251 | Learner Steps = 2600 | Steps = 21440 | Steps Per Second = 657.253 | Walltime = 427.331\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [07:09<03:50, 16.48s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 260 | Learner Steps = 2657 | Policy Loss = 1.075 | Push Down = 0.735 | Push Up = 0.709 | Q Average = 0.709 | Q Variance = 0.001 | Steps = 21728 | Walltime = 437.218\n",
            "[Evalloop] Episode Length = 107 | Episode Return = 0.807 | Episodes = 261 | Learner Steps = 2700 | Steps = 21835 | Steps Per Second = 683.022 | Walltime = 443.111\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [07:25<03:33, 16.43s/it][Learner] Advantage = 0.004 | Critic Loss = 0.002 | Episodes = 270 | Learner Steps = 2712 | Policy Loss = 1.054 | Push Down = 0.726 | Push Up = 0.702 | Q Average = 0.702 | Q Variance = 0.001 | Steps = 22461 | Walltime = 447.239\n",
            "[Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 270 | Learner Steps = 2784 | Policy Loss = 1.088 | Push Down = 0.728 | Push Up = 0.706 | Q Average = 0.706 | Q Variance = 0.000 | Steps = 22461 | Walltime = 457.325\n",
            "[Evalloop] Episode Length = 94 | Episode Return = 0.831 | Episodes = 271 | Learner Steps = 2800 | Steps = 22555 | Steps Per Second = 662.322 | Walltime = 459.569\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [07:42<03:20, 16.72s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 280 | Learner Steps = 2831 | Policy Loss = 1.085 | Push Down = 0.695 | Push Up = 0.668 | Q Average = 0.668 | Q Variance = 0.001 | Steps = 23103 | Walltime = 467.448\n",
            "[Evalloop] Episode Length = 102 | Episode Return = 0.816 | Episodes = 281 | Learner Steps = 2900 | Steps = 23205 | Steps Per Second = 742.087 | Walltime = 477.072\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [07:59<03:02, 16.63s/it][Learner] Advantage = -0.002 | Critic Loss = 0.001 | Episodes = 290 | Learner Steps = 2901 | Policy Loss = 1.103 | Push Down = 0.729 | Push Up = 0.699 | Q Average = 0.699 | Q Variance = 0.001 | Steps = 23722 | Walltime = 479.469\n",
            "[Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 290 | Learner Steps = 2972 | Policy Loss = 1.072 | Push Down = 0.710 | Push Up = 0.685 | Q Average = 0.686 | Q Variance = 0.001 | Steps = 23722 | Walltime = 489.520\n",
            "[Evalloop] Episode Length = 53 | Episode Return = 0.905 | Episodes = 291 | Learner Steps = 3000 | Steps = 23775 | Steps Per Second = 627.971 | Walltime = 493.379\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [08:15<02:45, 16.53s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 300 | Learner Steps = 3028 | Policy Loss = 1.088 | Push Down = 0.720 | Push Up = 0.695 | Q Average = 0.695 | Q Variance = 0.001 | Steps = 24292 | Walltime = 499.525\n",
            "[Learner] Advantage = -0.003 | Critic Loss = 0.001 | Episodes = 300 | Learner Steps = 3095 | Policy Loss = 1.095 | Push Down = 0.693 | Push Up = 0.666 | Q Average = 0.666 | Q Variance = 0.001 | Steps = 24292 | Walltime = 509.538\n",
            "[Evalloop] Episode Length = 104 | Episode Return = 0.813 | Episodes = 301 | Learner Steps = 3100 | Steps = 24396 | Steps Per Second = 642.161 | Walltime = 510.283\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [08:32<02:30, 16.69s/it][Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 310 | Learner Steps = 3148 | Policy Loss = 1.106 | Push Down = 0.704 | Push Up = 0.678 | Q Average = 0.679 | Q Variance = 0.001 | Steps = 24976 | Walltime = 519.543\n",
            "[Evalloop] Episode Length = 52 | Episode Return = 0.906 | Episodes = 311 | Learner Steps = 3200 | Steps = 25028 | Steps Per Second = 729.913 | Walltime = 526.839\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [08:48<02:12, 16.51s/it][Learner] Advantage = -0.006 | Critic Loss = 0.001 | Episodes = 320 | Learner Steps = 3206 | Policy Loss = 1.098 | Push Down = 0.698 | Push Up = 0.670 | Q Average = 0.670 | Q Variance = 0.001 | Steps = 25364 | Walltime = 529.649\n",
            "[Learner] Advantage = -0.003 | Critic Loss = 0.001 | Episodes = 320 | Learner Steps = 3277 | Policy Loss = 1.101 | Push Down = 0.737 | Push Up = 0.705 | Q Average = 0.705 | Q Variance = 0.001 | Steps = 25364 | Walltime = 539.728\n",
            "[Evalloop] Episode Length = 17 | Episode Return = 0.969 | Episodes = 321 | Learner Steps = 3300 | Steps = 25381 | Steps Per Second = 677.150 | Walltime = 543.070\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [09:05<01:56, 16.62s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 330 | Learner Steps = 3329 | Policy Loss = 1.069 | Push Down = 0.702 | Push Up = 0.676 | Q Average = 0.676 | Q Variance = 0.001 | Steps = 26133 | Walltime = 549.834\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 330 | Learner Steps = 3399 | Policy Loss = 1.047 | Push Down = 0.687 | Push Up = 0.667 | Q Average = 0.667 | Q Variance = 0.000 | Steps = 26133 | Walltime = 559.858\n",
            "[Evalloop] Episode Length = 45 | Episode Return = 0.919 | Episodes = 331 | Learner Steps = 3400 | Steps = 26178 | Steps Per Second = 581.937 | Walltime = 559.997\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [09:22<01:40, 16.72s/it][Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 340 | Learner Steps = 3452 | Policy Loss = 1.089 | Push Down = 0.717 | Push Up = 0.689 | Q Average = 0.689 | Q Variance = 0.001 | Steps = 26952 | Walltime = 569.875\n",
            "[Evalloop] Episode Length = 57 | Episode Return = 0.897 | Episodes = 341 | Learner Steps = 3500 | Steps = 27009 | Steps Per Second = 644.325 | Walltime = 576.415\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 35/40 [09:38<01:22, 16.43s/it][Learner] Advantage = -0.004 | Critic Loss = 0.001 | Episodes = 350 | Learner Steps = 3511 | Policy Loss = 1.110 | Push Down = 0.708 | Push Up = 0.683 | Q Average = 0.683 | Q Variance = 0.001 | Steps = 27337 | Walltime = 579.897\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 350 | Learner Steps = 3583 | Policy Loss = 1.104 | Push Down = 0.718 | Push Up = 0.690 | Q Average = 0.690 | Q Variance = 0.001 | Steps = 27337 | Walltime = 589.969\n",
            "[Evalloop] Episode Length = 88 | Episode Return = 0.842 | Episodes = 351 | Learner Steps = 3600 | Steps = 27425 | Steps Per Second = 770.714 | Walltime = 592.320\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [09:54<01:05, 16.30s/it][Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 360 | Learner Steps = 3641 | Policy Loss = 1.100 | Push Down = 0.671 | Push Up = 0.650 | Q Average = 0.650 | Q Variance = 0.000 | Steps = 27839 | Walltime = 600.089\n",
            "I0908 22:22:26.034375 140521074534272 savers.py:156] Saving checkpoint: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/checkpoints/crr_learner\n",
            "INFO:tensorflow:Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 22:22:26.331196 140521074534272 builder_impl.py:775] Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:22:27.785988 140521074534272 builder_impl.py:775] Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/critic/assets\n",
            "[Evalloop] Episode Length = 28 | Episode Return = 0.950 | Episodes = 361 | Learner Steps = 3700 | Steps = 27867 | Steps Per Second = 686.141 | Walltime = 610.042\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/40 [10:12<00:50, 16.82s/it][Learner] Advantage = -0.002 | Critic Loss = 0.001 | Episodes = 370 | Learner Steps = 3701 | Policy Loss = 1.098 | Push Down = 0.701 | Push Up = 0.675 | Q Average = 0.675 | Q Variance = 0.001 | Steps = 28527 | Walltime = 612.516\n",
            "[Learner] Advantage = 0.006 | Critic Loss = 0.003 | Episodes = 370 | Learner Steps = 3773 | Policy Loss = 1.065 | Push Down = 0.689 | Push Up = 0.660 | Q Average = 0.660 | Q Variance = 0.001 | Steps = 28527 | Walltime = 622.623\n",
            "[Evalloop] Episode Length = 99 | Episode Return = 0.822 | Episodes = 371 | Learner Steps = 3800 | Steps = 28626 | Steps Per Second = 648.830 | Walltime = 626.343\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [10:28<00:33, 16.51s/it][Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 380 | Learner Steps = 3833 | Policy Loss = 1.056 | Push Down = 0.686 | Push Up = 0.658 | Q Average = 0.658 | Q Variance = 0.001 | Steps = 28792 | Walltime = 632.742\n",
            "[Evalloop] Episode Length = 167 | Episode Return = 0.699 | Episodes = 381 | Learner Steps = 3900 | Steps = 28959 | Steps Per Second = 746.321 | Walltime = 641.994\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [10:44<00:16, 16.31s/it][Learner] Advantage = 0.006 | Critic Loss = 0.001 | Episodes = 390 | Learner Steps = 3901 | Policy Loss = 1.064 | Push Down = 0.718 | Push Up = 0.687 | Q Average = 0.687 | Q Variance = 0.001 | Steps = 29321 | Walltime = 644.181\n",
            "[Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 390 | Learner Steps = 3975 | Policy Loss = 1.102 | Push Down = 0.681 | Push Up = 0.656 | Q Average = 0.656 | Q Variance = 0.001 | Steps = 29321 | Walltime = 654.205\n",
            "[Evalloop] Episode Length = 128 | Episode Return = 0.770 | Episodes = 391 | Learner Steps = 4000 | Steps = 29449 | Steps Per Second = 752.720 | Walltime = 657.597\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [10:59<00:00, 16.49s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 22:23:24.804896 140521074534272 builder_impl.py:775] Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:23:24.871638 140521074534272 builder_impl.py:775] Assets written to: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:23:24.875728 140521074534272 savers.py:156] Saving checkpoint: /root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002/checkpoints/crr_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/c142af08-f21f-11ea-a25c-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3604\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 4439\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/q_average 0.6453277468681335\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 925.7577760219574\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/policy_loss 1.1034742593765259\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Learner/push_up 0.6452885866165161\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Learner/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/critic_loss 0.0007876874879002571\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/walltime 657.5971076488495\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599603804.0310588\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/push_down 0.6750860214233398\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/advantage 0.001396413892507553\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          Learner/q_variance 0.0008154633105732501\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 88\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.8416000008583069\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/walltime 657.5971076488495\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 738.8802293319027\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      EvalLoop/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 29756\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch_counter 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/episodes 390\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Learner/steps 29321\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/c142af08-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group crrql-0.01-exp-eps0-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 40 media file(s), 10 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599602882\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.7 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20200908_222337-1599603817\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m1599603817\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/kmeco/offline-rl/runs/1599603817\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
            "\n",
            "_____Evaluating counts for all state action pairs_____ \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [04:21<00:00,  3.83it/s]\n",
            "I0908 22:28:02.506886 140190765471616 savers.py:166] Attempting to restoring checkpoint: None\n",
            "  0%|                                                    | 0/40 [00:00<?, ?it/s]I0908 22:28:03.841215 140190765471616 savers.py:156] Saving checkpoint: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/checkpoints/crr_learner\n",
            "INFO:tensorflow:Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 22:28:04.166246 140190765471616 builder_impl.py:775] Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:28:04.267636 140190765471616 builder_impl.py:775] Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/critic/assets\n",
            "[Learner] Advantage = -0.003 | Critic Loss = 0.003 | Learner Steps = 62 | Policy Loss = 1.099 | Push Down = 1.082 | Push Up = 1.040 | Q Average = 1.040 | Q Variance = 0.002 | Walltime = 9.221\n",
            "[Evalloop] Episode Length = 77 | Episode Return = 0.861 | Episodes = 1 | Learner Steps = 100 | Steps = 77 | Steps Per Second = 348.597 | Walltime = 14.483\n",
            "  2%|‚ñà                                           | 1/40 [00:17<11:11, 17.21s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 10 | Learner Steps = 115 | Policy Loss = 1.101 | Push Down = 1.042 | Push Up = 1.008 | Q Average = 1.008 | Q Variance = 0.001 | Steps = 698 | Walltime = 19.327\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 10 | Learner Steps = 189 | Policy Loss = 1.097 | Push Down = 1.041 | Push Up = 1.018 | Q Average = 1.018 | Q Variance = 0.001 | Steps = 698 | Walltime = 29.427\n",
            "[Evalloop] Episode Length = 319 | Episode Return = 0.426 | Episodes = 11 | Learner Steps = 200 | Steps = 1017 | Steps Per Second = 761.283 | Walltime = 30.894\n",
            "  5%|‚ñà‚ñà‚ñè                                         | 2/40 [00:33<10:48, 17.08s/it][Learner] Advantage = 0.003 | Critic Loss = 0.000 | Episodes = 20 | Learner Steps = 240 | Policy Loss = 1.117 | Push Down = 1.006 | Push Up = 0.986 | Q Average = 0.986 | Q Variance = 0.000 | Steps = 1857 | Walltime = 39.478\n",
            "[Evalloop] Episode Length = 206 | Episode Return = 0.629 | Episodes = 21 | Learner Steps = 300 | Steps = 2063 | Steps Per Second = 755.524 | Walltime = 47.739\n",
            "  8%|‚ñà‚ñà‚ñà‚ñé                                        | 3/40 [00:50<10:22, 16.82s/it][Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 30 | Learner Steps = 301 | Policy Loss = 1.089 | Push Down = 1.005 | Push Up = 0.985 | Q Average = 0.985 | Q Variance = 0.000 | Steps = 2601 | Walltime = 50.310\n",
            "[Learner] Advantage = -0.002 | Critic Loss = 0.000 | Episodes = 30 | Learner Steps = 373 | Policy Loss = 1.098 | Push Down = 0.984 | Push Up = 0.968 | Q Average = 0.968 | Q Variance = 0.000 | Steps = 2601 | Walltime = 60.389\n",
            "[Evalloop] Episode Length = 11 | Episode Return = 0.980 | Episodes = 31 | Learner Steps = 400 | Steps = 2612 | Steps Per Second = 635.553 | Walltime = 64.154\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñç                                       | 4/40 [01:06<10:05, 16.81s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 40 | Learner Steps = 425 | Policy Loss = 1.074 | Push Down = 0.970 | Push Up = 0.955 | Q Average = 0.955 | Q Variance = 0.000 | Steps = 3494 | Walltime = 70.429\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 40 | Learner Steps = 497 | Policy Loss = 1.121 | Push Down = 0.963 | Push Up = 0.949 | Q Average = 0.949 | Q Variance = 0.000 | Steps = 3494 | Walltime = 80.460\n",
            "[Evalloop] Episode Length = 31 | Episode Return = 0.944 | Episodes = 41 | Learner Steps = 500 | Steps = 3525 | Steps Per Second = 747.493 | Walltime = 80.933\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                      | 5/40 [01:23<09:50, 16.86s/it][Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 50 | Learner Steps = 548 | Policy Loss = 1.091 | Push Down = 0.954 | Push Up = 0.941 | Q Average = 0.941 | Q Variance = 0.000 | Steps = 4700 | Walltime = 90.537\n",
            "[Evalloop] Episode Length = 14 | Episode Return = 0.975 | Episodes = 51 | Learner Steps = 600 | Steps = 4714 | Steps Per Second = 691.396 | Walltime = 97.774\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                     | 6/40 [01:39<09:24, 16.61s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 60 | Learner Steps = 605 | Policy Loss = 1.095 | Push Down = 0.939 | Push Up = 0.926 | Q Average = 0.926 | Q Variance = 0.000 | Steps = 5090 | Walltime = 100.645\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 60 | Learner Steps = 680 | Policy Loss = 1.121 | Push Down = 0.929 | Push Up = 0.914 | Q Average = 0.914 | Q Variance = 0.000 | Steps = 5090 | Walltime = 110.767\n",
            "[Evalloop] Episode Length = 82 | Episode Return = 0.852 | Episodes = 61 | Learner Steps = 700 | Steps = 5172 | Steps Per Second = 773.184 | Walltime = 113.472\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                    | 7/40 [01:56<09:10, 16.67s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 70 | Learner Steps = 729 | Policy Loss = 1.097 | Push Down = 0.910 | Push Up = 0.898 | Q Average = 0.897 | Q Variance = 0.000 | Steps = 6552 | Walltime = 120.892\n",
            "[Evalloop] Episode Length = 137 | Episode Return = 0.753 | Episodes = 71 | Learner Steps = 800 | Steps = 6689 | Steps Per Second = 743.472 | Walltime = 130.759\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 8/40 [02:13<08:52, 16.64s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 80 | Learner Steps = 801 | Policy Loss = 1.084 | Push Down = 0.909 | Push Up = 0.896 | Q Average = 0.896 | Q Variance = 0.000 | Steps = 7455 | Walltime = 133.490\n",
            "[Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 80 | Learner Steps = 875 | Policy Loss = 1.083 | Push Down = 0.892 | Push Up = 0.880 | Q Average = 0.880 | Q Variance = 0.000 | Steps = 7455 | Walltime = 143.629\n",
            "[Evalloop] Episode Length = 51 | Episode Return = 0.908 | Episodes = 81 | Learner Steps = 900 | Steps = 7506 | Steps Per Second = 761.228 | Walltime = 147.119\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 9/40 [02:30<08:41, 16.82s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 90 | Learner Steps = 923 | Policy Loss = 1.095 | Push Down = 0.889 | Push Up = 0.875 | Q Average = 0.875 | Q Variance = 0.000 | Steps = 8670 | Walltime = 153.748\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 90 | Learner Steps = 996 | Policy Loss = 1.083 | Push Down = 0.889 | Push Up = 0.876 | Q Average = 0.876 | Q Variance = 0.000 | Steps = 8670 | Walltime = 163.807\n",
            "[Evalloop] Episode Length = 130 | Episode Return = 0.766 | Episodes = 91 | Learner Steps = 1000 | Steps = 8800 | Steps Per Second = 740.188 | Walltime = 164.339\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 10/40 [02:47<08:23, 16.80s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 100 | Learner Steps = 1047 | Policy Loss = 1.089 | Push Down = 0.874 | Push Up = 0.857 | Q Average = 0.857 | Q Variance = 0.000 | Steps = 9865 | Walltime = 173.888\n",
            "[Evalloop] Episode Length = 78 | Episode Return = 0.860 | Episodes = 101 | Learner Steps = 1100 | Steps = 9943 | Steps Per Second = 780.280 | Walltime = 181.342\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 11/40 [03:03<08:03, 16.67s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1102 | Policy Loss = 1.077 | Push Down = 0.865 | Push Up = 0.852 | Q Average = 0.852 | Q Variance = 0.000 | Steps = 10599 | Walltime = 183.984\n",
            "[Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 110 | Learner Steps = 1172 | Policy Loss = 1.109 | Push Down = 0.841 | Push Up = 0.829 | Q Average = 0.829 | Q Variance = 0.000 | Steps = 10599 | Walltime = 194.061\n",
            "[Evalloop] Episode Length = 119 | Episode Return = 0.786 | Episodes = 111 | Learner Steps = 1200 | Steps = 10718 | Steps Per Second = 713.424 | Walltime = 197.962\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 12/40 [03:21<07:53, 16.91s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 120 | Learner Steps = 1221 | Policy Loss = 1.110 | Push Down = 0.837 | Push Up = 0.821 | Q Average = 0.821 | Q Variance = 0.000 | Steps = 11573 | Walltime = 204.157\n",
            "[Learner] Advantage = -0.000 | Critic Loss = 0.000 | Episodes = 120 | Learner Steps = 1292 | Policy Loss = 1.085 | Push Down = 0.839 | Push Up = 0.826 | Q Average = 0.826 | Q Variance = 0.000 | Steps = 11573 | Walltime = 214.186\n",
            "[Evalloop] Episode Length = 188 | Episode Return = 0.662 | Episodes = 121 | Learner Steps = 1300 | Steps = 11761 | Steps Per Second = 706.600 | Walltime = 215.337\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 13/40 [03:38<07:38, 16.97s/it][Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 130 | Learner Steps = 1342 | Policy Loss = 1.089 | Push Down = 0.836 | Push Up = 0.821 | Q Average = 0.821 | Q Variance = 0.000 | Steps = 12665 | Walltime = 224.302\n",
            "[Evalloop] Episode Length = 111 | Episode Return = 0.800 | Episodes = 131 | Learner Steps = 1400 | Steps = 12776 | Steps Per Second = 770.980 | Walltime = 232.369\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 14/40 [03:54<07:18, 16.86s/it][Learner] Advantage = 0.000 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1401 | Policy Loss = 1.072 | Push Down = 0.824 | Push Up = 0.810 | Q Average = 0.810 | Q Variance = 0.000 | Steps = 13472 | Walltime = 235.051\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.000 | Episodes = 140 | Learner Steps = 1472 | Policy Loss = 1.074 | Push Down = 0.813 | Push Up = 0.798 | Q Average = 0.798 | Q Variance = 0.000 | Steps = 13472 | Walltime = 245.064\n",
            "[Evalloop] Episode Length = 102 | Episode Return = 0.816 | Episodes = 141 | Learner Steps = 1500 | Steps = 13574 | Steps Per Second = 743.134 | Walltime = 248.894\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 15/40 [04:10<06:53, 16.55s/it][Learner] Advantage = -0.001 | Critic Loss = 0.000 | Episodes = 150 | Learner Steps = 1532 | Policy Loss = 1.101 | Push Down = 0.794 | Push Up = 0.779 | Q Average = 0.779 | Q Variance = 0.000 | Steps = 13830 | Walltime = 255.185\n",
            "[Evalloop] Episode Length = 8 | Episode Return = 0.986 | Episodes = 151 | Learner Steps = 1600 | Steps = 13838 | Steps Per Second = 710.282 | Walltime = 264.512\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 16/40 [04:27<06:35, 16.50s/it][Learner] Advantage = 0.002 | Critic Loss = 0.000 | Episodes = 160 | Learner Steps = 1601 | Policy Loss = 1.069 | Push Down = 0.797 | Push Up = 0.780 | Q Average = 0.780 | Q Variance = 0.000 | Steps = 14719 | Walltime = 267.245\n",
            "[Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 160 | Learner Steps = 1673 | Policy Loss = 1.067 | Push Down = 0.795 | Push Up = 0.779 | Q Average = 0.779 | Q Variance = 0.000 | Steps = 14719 | Walltime = 277.376\n",
            "[Evalloop] Episode Length = 29 | Episode Return = 0.948 | Episodes = 161 | Learner Steps = 1700 | Steps = 14748 | Steps Per Second = 774.157 | Walltime = 281.073\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 17/40 [04:44<06:22, 16.64s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 170 | Learner Steps = 1724 | Policy Loss = 1.092 | Push Down = 0.773 | Push Up = 0.755 | Q Average = 0.755 | Q Variance = 0.000 | Steps = 15447 | Walltime = 287.418\n",
            "[Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 170 | Learner Steps = 1796 | Policy Loss = 1.090 | Push Down = 0.770 | Push Up = 0.753 | Q Average = 0.753 | Q Variance = 0.000 | Steps = 15447 | Walltime = 297.490\n",
            "[Evalloop] Episode Length = 67 | Episode Return = 0.879 | Episodes = 171 | Learner Steps = 1800 | Steps = 15514 | Steps Per Second = 763.923 | Walltime = 298.036\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 18/40 [05:00<06:01, 16.44s/it][Learner] Advantage = -0.002 | Critic Loss = 0.000 | Episodes = 180 | Learner Steps = 1854 | Policy Loss = 1.119 | Push Down = 0.790 | Push Up = 0.773 | Q Average = 0.773 | Q Variance = 0.000 | Steps = 15928 | Walltime = 307.564\n",
            "[Evalloop] Episode Length = 100 | Episode Return = 0.820 | Episodes = 181 | Learner Steps = 1900 | Steps = 16028 | Steps Per Second = 647.898 | Walltime = 313.875\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 19/40 [05:16<05:43, 16.33s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 190 | Learner Steps = 1910 | Policy Loss = 1.091 | Push Down = 0.775 | Push Up = 0.756 | Q Average = 0.756 | Q Variance = 0.000 | Steps = 16575 | Walltime = 317.567\n",
            "[Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 190 | Learner Steps = 1983 | Policy Loss = 1.095 | Push Down = 0.758 | Push Up = 0.741 | Q Average = 0.741 | Q Variance = 0.000 | Steps = 16575 | Walltime = 327.606\n",
            "[Evalloop] Episode Length = 35 | Episode Return = 0.937 | Episodes = 191 | Learner Steps = 2000 | Steps = 16610 | Steps Per Second = 683.942 | Walltime = 330.025\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20/40 [05:32<05:27, 16.37s/it][Learner] Advantage = -0.002 | Critic Loss = 0.000 | Episodes = 200 | Learner Steps = 2037 | Policy Loss = 1.087 | Push Down = 0.748 | Push Up = 0.730 | Q Average = 0.730 | Q Variance = 0.000 | Steps = 17412 | Walltime = 337.749\n",
            "[Evalloop] Episode Length = 39 | Episode Return = 0.930 | Episodes = 201 | Learner Steps = 2100 | Steps = 17451 | Steps Per Second = 735.419 | Walltime = 346.438\n",
            "/content/visualization.py:111: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  fig = plt.figure(figsize=(17, 12))\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                    | 21/40 [05:48<05:09, 16.27s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 210 | Learner Steps = 2101 | Policy Loss = 1.091 | Push Down = 0.743 | Push Up = 0.726 | Q Average = 0.726 | Q Variance = 0.000 | Steps = 17995 | Walltime = 348.750\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 210 | Learner Steps = 2173 | Policy Loss = 1.069 | Push Down = 0.759 | Push Up = 0.738 | Q Average = 0.738 | Q Variance = 0.000 | Steps = 17995 | Walltime = 358.802\n",
            "[Evalloop] Episode Length = 17 | Episode Return = 0.969 | Episodes = 211 | Learner Steps = 2200 | Steps = 18012 | Steps Per Second = 666.665 | Walltime = 362.620\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 22/40 [06:05<04:57, 16.51s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 220 | Learner Steps = 2223 | Policy Loss = 1.058 | Push Down = 0.744 | Push Up = 0.722 | Q Average = 0.722 | Q Variance = 0.000 | Steps = 18585 | Walltime = 368.905\n",
            "[Learner] Advantage = 0.001 | Critic Loss = 0.000 | Episodes = 220 | Learner Steps = 2296 | Policy Loss = 1.092 | Push Down = 0.722 | Push Up = 0.702 | Q Average = 0.702 | Q Variance = 0.000 | Steps = 18585 | Walltime = 378.931\n",
            "[Evalloop] Episode Length = 4 | Episode Return = 0.993 | Episodes = 221 | Learner Steps = 2300 | Steps = 18589 | Steps Per Second = 613.113 | Walltime = 379.504\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 23/40 [06:21<04:37, 16.30s/it][Learner] Advantage = 0.003 | Critic Loss = 0.000 | Episodes = 230 | Learner Steps = 2355 | Policy Loss = 1.078 | Push Down = 0.721 | Push Up = 0.703 | Q Average = 0.703 | Q Variance = 0.000 | Steps = 19030 | Walltime = 388.990\n",
            "[Evalloop] Episode Length = 10 | Episode Return = 0.982 | Episodes = 231 | Learner Steps = 2400 | Steps = 19040 | Steps Per Second = 645.834 | Walltime = 395.088\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 24/40 [06:37<04:19, 16.24s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 240 | Learner Steps = 2410 | Policy Loss = 1.089 | Push Down = 0.748 | Push Up = 0.724 | Q Average = 0.724 | Q Variance = 0.000 | Steps = 19835 | Walltime = 399.054\n",
            "[Learner] Advantage = 0.005 | Critic Loss = 0.001 | Episodes = 240 | Learner Steps = 2484 | Policy Loss = 1.055 | Push Down = 0.747 | Push Up = 0.723 | Q Average = 0.723 | Q Variance = 0.001 | Steps = 19835 | Walltime = 409.154\n",
            "[Evalloop] Episode Length = 25 | Episode Return = 0.955 | Episodes = 241 | Learner Steps = 2500 | Steps = 19860 | Steps Per Second = 715.742 | Walltime = 411.385\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 25/40 [06:53<04:02, 16.14s/it][Learner] Advantage = 0.005 | Critic Loss = 0.001 | Episodes = 250 | Learner Steps = 2540 | Policy Loss = 1.058 | Push Down = 0.749 | Push Up = 0.724 | Q Average = 0.724 | Q Variance = 0.001 | Steps = 20372 | Walltime = 419.228\n",
            "[Evalloop] Episode Length = 5 | Episode Return = 0.991 | Episodes = 251 | Learner Steps = 2600 | Steps = 20377 | Steps Per Second = 613.346 | Walltime = 427.431\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 26/40 [07:09<03:44, 16.03s/it][Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 260 | Learner Steps = 2601 | Policy Loss = 1.094 | Push Down = 0.738 | Push Up = 0.719 | Q Average = 0.719 | Q Variance = 0.000 | Steps = 20759 | Walltime = 429.418\n",
            "[Learner] Advantage = -0.000 | Critic Loss = 0.000 | Episodes = 260 | Learner Steps = 2674 | Policy Loss = 1.095 | Push Down = 0.743 | Push Up = 0.721 | Q Average = 0.721 | Q Variance = 0.000 | Steps = 20759 | Walltime = 439.537\n",
            "[Evalloop] Episode Length = 63 | Episode Return = 0.887 | Episodes = 261 | Learner Steps = 2700 | Steps = 20822 | Steps Per Second = 753.739 | Walltime = 443.096\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 27/40 [07:25<03:29, 16.11s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 270 | Learner Steps = 2729 | Policy Loss = 1.080 | Push Down = 0.747 | Push Up = 0.719 | Q Average = 0.719 | Q Variance = 0.001 | Steps = 21569 | Walltime = 449.622\n",
            "[Evalloop] Episode Length = 97 | Episode Return = 0.825 | Episodes = 271 | Learner Steps = 2800 | Steps = 21666 | Steps Per Second = 626.319 | Walltime = 459.522\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 28/40 [07:42<03:17, 16.44s/it][Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 280 | Learner Steps = 2801 | Policy Loss = 1.098 | Push Down = 0.739 | Push Up = 0.714 | Q Average = 0.714 | Q Variance = 0.001 | Steps = 22213 | Walltime = 462.938\n",
            "[Learner] Advantage = 0.000 | Critic Loss = 0.001 | Episodes = 280 | Learner Steps = 2874 | Policy Loss = 1.067 | Push Down = 0.720 | Push Up = 0.699 | Q Average = 0.699 | Q Variance = 0.000 | Steps = 22213 | Walltime = 473.034\n",
            "[Evalloop] Episode Length = 150 | Episode Return = 0.730 | Episodes = 281 | Learner Steps = 2900 | Steps = 22363 | Steps Per Second = 784.497 | Walltime = 476.619\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 29/40 [07:58<02:59, 16.30s/it][Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 290 | Learner Steps = 2931 | Policy Loss = 1.100 | Push Down = 0.708 | Push Up = 0.689 | Q Average = 0.689 | Q Variance = 0.000 | Steps = 22789 | Walltime = 483.050\n",
            "[Evalloop] Episode Length = 11 | Episode Return = 0.980 | Episodes = 291 | Learner Steps = 3000 | Steps = 22800 | Steps Per Second = 662.769 | Walltime = 492.706\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 30/40 [08:15<02:43, 16.35s/it][Learner] Advantage = 0.003 | Critic Loss = 0.002 | Episodes = 300 | Learner Steps = 3001 | Policy Loss = 1.073 | Push Down = 0.704 | Push Up = 0.681 | Q Average = 0.681 | Q Variance = 0.001 | Steps = 23595 | Walltime = 495.404\n",
            "[Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 300 | Learner Steps = 3069 | Policy Loss = 1.087 | Push Down = 0.725 | Push Up = 0.697 | Q Average = 0.698 | Q Variance = 0.001 | Steps = 23595 | Walltime = 505.521\n",
            "[Evalloop] Episode Length = 48 | Episode Return = 0.914 | Episodes = 301 | Learner Steps = 3100 | Steps = 23643 | Steps Per Second = 620.606 | Walltime = 509.732\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 31/40 [08:32<02:28, 16.48s/it][Learner] Advantage = -0.002 | Critic Loss = 0.001 | Episodes = 310 | Learner Steps = 3126 | Policy Loss = 1.082 | Push Down = 0.727 | Push Up = 0.701 | Q Average = 0.701 | Q Variance = 0.001 | Steps = 24234 | Walltime = 515.592\n",
            "[Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 310 | Learner Steps = 3199 | Policy Loss = 1.095 | Push Down = 0.708 | Push Up = 0.681 | Q Average = 0.681 | Q Variance = 0.001 | Steps = 24234 | Walltime = 525.718\n",
            "[Evalloop] Episode Length = 58 | Episode Return = 0.896 | Episodes = 311 | Learner Steps = 3200 | Steps = 24292 | Steps Per Second = 670.537 | Walltime = 525.858\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 32/40 [08:47<02:10, 16.29s/it][Learner] Advantage = -0.002 | Critic Loss = 0.000 | Episodes = 320 | Learner Steps = 3258 | Policy Loss = 1.117 | Push Down = 0.711 | Push Up = 0.687 | Q Average = 0.687 | Q Variance = 0.001 | Steps = 24675 | Walltime = 535.808\n",
            "[Evalloop] Episode Length = 26 | Episode Return = 0.953 | Episodes = 321 | Learner Steps = 3300 | Steps = 24701 | Steps Per Second = 582.480 | Walltime = 541.580\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 33/40 [09:03<01:53, 16.22s/it][Learner] Advantage = 0.001 | Critic Loss = 0.001 | Episodes = 330 | Learner Steps = 3314 | Policy Loss = 1.089 | Push Down = 0.730 | Push Up = 0.703 | Q Average = 0.703 | Q Variance = 0.001 | Steps = 25350 | Walltime = 545.865\n",
            "[Learner] Advantage = 0.003 | Critic Loss = 0.001 | Episodes = 330 | Learner Steps = 3386 | Policy Loss = 1.066 | Push Down = 0.722 | Push Up = 0.691 | Q Average = 0.691 | Q Variance = 0.001 | Steps = 25350 | Walltime = 555.992\n",
            "[Evalloop] Episode Length = 57 | Episode Return = 0.897 | Episodes = 331 | Learner Steps = 3400 | Steps = 25407 | Steps Per Second = 680.142 | Walltime = 557.898\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 34/40 [09:20<01:37, 16.18s/it][Learner] Advantage = 0.000 | Critic Loss = 0.001 | Episodes = 340 | Learner Steps = 3442 | Policy Loss = 1.067 | Push Down = 0.746 | Push Up = 0.713 | Q Average = 0.713 | Q Variance = 0.001 | Steps = 25832 | Walltime = 566.060\n",
            "[Evalloop] Episode Length = 18 | Episode Return = 0.968 | Episodes = 341 | Learner Steps = 3500 | Steps = 25850 | Steps Per Second = 682.272 | Walltime = 574.327\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 35/40 [09:36<01:20, 16.19s/it][Learner] Advantage = -0.003 | Critic Loss = 0.001 | Episodes = 350 | Learner Steps = 3501 | Policy Loss = 1.107 | Push Down = 0.744 | Push Up = 0.711 | Q Average = 0.711 | Q Variance = 0.001 | Steps = 26168 | Walltime = 576.350\n",
            "[Learner] Advantage = 0.008 | Critic Loss = 0.001 | Episodes = 350 | Learner Steps = 3573 | Policy Loss = 1.062 | Push Down = 0.728 | Push Up = 0.700 | Q Average = 0.700 | Q Variance = 0.001 | Steps = 26168 | Walltime = 586.352\n",
            "[Evalloop] Episode Length = 110 | Episode Return = 0.802 | Episodes = 351 | Learner Steps = 3600 | Steps = 26278 | Steps Per Second = 752.872 | Walltime = 590.187\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 36/40 [09:53<01:06, 16.52s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 360 | Learner Steps = 3621 | Policy Loss = 1.066 | Push Down = 0.715 | Push Up = 0.692 | Q Average = 0.692 | Q Variance = 0.001 | Steps = 26691 | Walltime = 596.477\n",
            "I0908 22:38:04.105084 140190765471616 savers.py:156] Saving checkpoint: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/checkpoints/crr_learner\n",
            "INFO:tensorflow:Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 22:38:04.389417 140190765471616 builder_impl.py:775] Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:38:04.455289 140190765471616 builder_impl.py:775] Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/critic/assets\n",
            "[Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 360 | Learner Steps = 3690 | Policy Loss = 1.076 | Push Down = 0.714 | Push Up = 0.691 | Q Average = 0.691 | Q Variance = 0.000 | Steps = 26691 | Walltime = 606.536\n",
            "[Evalloop] Episode Length = 41 | Episode Return = 0.926 | Episodes = 361 | Learner Steps = 3700 | Steps = 26732 | Steps Per Second = 744.115 | Walltime = 607.916\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 37/40 [10:09<00:49, 16.45s/it][Learner] Advantage = 0.004 | Critic Loss = 0.001 | Episodes = 370 | Learner Steps = 3749 | Policy Loss = 1.103 | Push Down = 0.751 | Push Up = 0.718 | Q Average = 0.718 | Q Variance = 0.001 | Steps = 27064 | Walltime = 616.607\n",
            "[Evalloop] Episode Length = 19 | Episode Return = 0.966 | Episodes = 371 | Learner Steps = 3800 | Steps = 27083 | Steps Per Second = 693.720 | Walltime = 623.768\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 38/40 [10:25<00:32, 16.28s/it][Learner] Advantage = -0.000 | Critic Loss = 0.001 | Episodes = 380 | Learner Steps = 3807 | Policy Loss = 1.077 | Push Down = 0.716 | Push Up = 0.683 | Q Average = 0.683 | Q Variance = 0.001 | Steps = 27386 | Walltime = 626.676\n",
            "[Learner] Advantage = 0.006 | Critic Loss = 0.001 | Episodes = 380 | Learner Steps = 3879 | Policy Loss = 1.085 | Push Down = 0.723 | Push Up = 0.694 | Q Average = 0.694 | Q Variance = 0.001 | Steps = 27386 | Walltime = 636.752\n",
            "[Evalloop] Episode Length = 22 | Episode Return = 0.960 | Episodes = 381 | Learner Steps = 3900 | Steps = 27408 | Steps Per Second = 693.456 | Walltime = 639.754\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 39/40 [10:42<00:16, 16.35s/it][Learner] Advantage = 0.002 | Critic Loss = 0.001 | Episodes = 390 | Learner Steps = 3933 | Policy Loss = 1.070 | Push Down = 0.706 | Push Up = 0.676 | Q Average = 0.676 | Q Variance = 0.001 | Steps = 28122 | Walltime = 646.895\n",
            "[Evalloop] Episode Length = 15 | Episode Return = 0.973 | Episodes = 391 | Learner Steps = 4000 | Steps = 28137 | Steps Per Second = 702.603 | Walltime = 656.556\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [10:59<00:00, 16.48s/it]\n",
            "INFO:tensorflow:Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/raw_policy/assets\n",
            "I0908 22:39:02.369386 140190765471616 builder_impl.py:775] Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/raw_policy/assets\n",
            "INFO:tensorflow:Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:39:02.443716 140190765471616 builder_impl.py:775] Assets written to: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/snapshots/critic/assets\n",
            "I0908 22:39:02.447701 140190765471616 savers.py:156] Saving checkpoint: /root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002/checkpoints/crr_learner\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/acme/ee9d7e86-f221-11ea-8979-0242ac1c0002)... Done. 0.1s\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3767\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  _timestamp 1599604741.575639\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       Learner/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       _step 4439\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/q_average 0.6768724918365479\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/walltime 656.5562098026276\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             Learner/push_up 0.6770469546318054\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          Learner/q_variance 0.0010184857528656721\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/advantage 0.0023514553904533386\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/policy_loss 1.0647265911102295\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         Learner/critic_loss 0.0007992498576641083\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           Learner/push_down 0.708389937877655\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    _runtime 928.2304527759552\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              EvalLoop/steps 28847\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/episodes 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           EvalLoop/walltime 656.5562098026276\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_return 0.8848000168800354\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     EvalLoop/episode_length 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      EvalLoop/learner_steps 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   EvalLoop/steps_per_second 728.5117580488017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch_counter 39\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               Learner/steps 28122\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            Learner/episodes 390\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              checkpoint_dir /root/acme/ee9d7e86-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       group crrql-0.01-exp-eps0-...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 6 W&B file(s), 40 media file(s), 10 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced: https://app.wandb.ai/kmeco/offline-rl/runs/1599603817\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}